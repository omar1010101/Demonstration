{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2c8e05-b210-4fe6-be58-4deca4b29d1d",
   "metadata": {},
   "source": [
    "# Classification of a vectors of random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295fb5d-ba9f-4156-8a1b-2e1005963dd7",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "For the demonstration, I choose to use synthetic data to simplify things and save time\n",
    "### Predictors and targets\n",
    "- The predictor $X$ is a 10-dimensional vector where the entries are comming from a normal distribution $N \\left( \\mu, \\sigma \\right)$\n",
    "I choose to fix $\\mu = 100$ and to have instances where the standard deviation $\\sigma \\in \\{1, 2, 3, 4, 5\\}$\n",
    "- So for a given instance, the predictor is $X$ and the target $Y = \\sigma$\n",
    "### Goal\n",
    "Our goal is to classify i.e. to predict the standard deviation $\\sigma$ based on the vector $X$\n",
    "### Approach\n",
    "- We split data into training, validation and test data\n",
    "- We use a feedforward neural network, there is no need to have a sequence-oriented model such as RNN, because the entries of the vector are independant\n",
    "- We choose to fix epochs in 10, and tune other hyperparameters using the optuna framework, which uses a bayesian optimization approach. An approach that is similar to the popular idea in reinforecement learning, explore and exploit. So it explore the hyperparameter space in a non-exaustive way, but uses previous experiences to guide future explorations.\n",
    "- I have used the accuaracy metric as the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b7e4ec-e9a3-4fc3-b060-b150142812b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omarg\\anaconda3\\envs\\new\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65de784f-cf63-45ee-8711-ef3da68f64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = 10000 #number of instances\n",
    "num_features = 10 #number of features\n",
    "s_values = [1, 2, 3, 4, 5] #the classes, i.e. the standard deviation of the sampling distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbd626e-002b-4044-9893-693399e0e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2492ab-26f8-4559-8e01-dfbbc7e7a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data\n",
    "for _ in range(num_instances):\n",
    "    s = np.random.choice(s_values)\n",
    "    x = np.random.normal(loc=100, scale=s, size=num_features)#loc : mean, scale:standard deviation, size: the vector shape\n",
    "    y = s\n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34eed5c2-ffa4-484c-ba69-c464f0469926",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26b37f3-f3b9-4877-8c4b-6e65c12e2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d9fbaf-fd00-47a0-8060-6adc62905719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106.97252557 101.53964421  98.79761814 108.08184519  94.68424195\n",
      "   96.52768656  99.57866773 100.79549978 100.51348269  94.14896118]\n",
      " [ 98.44498226  93.82214874 104.06849009  99.28200967 105.18988478\n",
      "   98.12541208 105.29406747 105.04727376  98.89638568  96.26732825]\n",
      " [ 99.45452167  99.62915417 100.99268478 100.04924124  98.85569226\n",
      "   99.31898887  99.71365697 100.64984672 100.20770955  99.31519275]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129ded28-4292-473d-9547-1bb1a2a7af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4066b26-64ab-46dd-bffb-362840317ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For s = 1 --> 0.2045\n",
      "For s = 2 --> 0.1918\n",
      "For s = 3 --> 0.1984\n",
      "For s = 4 --> 0.2041\n",
      "For s = 5 --> 0.2012\n"
     ]
    }
   ],
   "source": [
    "# verifying if the resulting instances are balanced over classes\n",
    "for s in s_values:\n",
    "    print('For s =', s, '-->',len(Y[Y==s])/len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984d559b-5583-452b-adc6-defa357a83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting with making sure that the resulting splits have the same distribution as the original data\n",
    "# This is important especialy for the test data, so to be representative of real external data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49cb4369-9574-4ec3-8f56-d781a3b19bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For s = 1 --> 0.2045\n",
      "For s = 2 --> 0.19175\n",
      "For s = 3 --> 0.198375\n",
      "For s = 4 --> 0.204125\n",
      "For s = 5 --> 0.20125\n"
     ]
    }
   ],
   "source": [
    "# verifying balance after splitting\n",
    "for s in s_values:\n",
    "    print('For s =', s, '-->',len(Y_train[Y_train==s])/len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3218230-8fe5-4dfe-8b8d-16c737d57928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training data into one for training and one for validating\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, shuffle=True, random_state=42, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81131760-d7db-4da8-85f2-fdaf190a3a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 10)\n",
      "(1600, 10)\n",
      "(2000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89261147-90df-4edb-893e-85cea861711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype = torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype = torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f906c5-42b0-4dfc-97d9-31e256b9f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset(X_train, Y_train)\n",
    "validation_data = dataset(X_val, Y_val)\n",
    "testing_data = dataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4690fd7-5aff-4277-a762-3d1c2fdbdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_data, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4763813f-855a-4796-be1d-242deb7d804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 20:04:14,597] A new study created in memory with name: no-name-74cdd1c8-162e-4a68-a56b-4604af64a165\n",
      "[I 2025-01-03 20:04:17,001] Trial 0 finished with value: 0.223125 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'dropout_l0': 0.46757447677315583, 'optimizer': 'Adam', 'lr': 0.0003927493984493093, 'l2': 0.03322835901401022}. Best is trial 0 with value: 0.223125.\n",
      "[I 2025-01-03 20:04:17,746] Trial 1 finished with value: 0.204375 and parameters: {'n_layers': 3, 'n_units_l0': 108, 'dropout_l0': 0.28481278795827947, 'n_units_l1': 127, 'dropout_l1': 0.3712138942672482, 'n_units_l2': 30, 'dropout_l2': 0.4168533690452827, 'optimizer': 'SGD', 'lr': 0.0003439331845395555, 'l2': 0.419824542805444}. Best is trial 0 with value: 0.223125.\n",
      "[I 2025-01-03 20:04:18,531] Trial 2 finished with value: 0.200625 and parameters: {'n_layers': 3, 'n_units_l0': 113, 'dropout_l0': 0.28867890329649737, 'n_units_l1': 16, 'dropout_l1': 0.20515925287217637, 'n_units_l2': 99, 'dropout_l2': 0.4653915363366217, 'optimizer': 'RMSprop', 'lr': 2.4211437143154265e-05, 'l2': 0.0015361294375204912}. Best is trial 0 with value: 0.223125.\n",
      "[I 2025-01-03 20:04:19,079] Trial 3 finished with value: 0.255625 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'dropout_l0': 0.39584165330498183, 'optimizer': 'SGD', 'lr': 0.0007817860406073219, 'l2': 0.03960426107052934}. Best is trial 3 with value: 0.255625.\n",
      "[I 2025-01-03 20:04:19,905] Trial 4 finished with value: 0.204375 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'dropout_l0': 0.270142425264269, 'n_units_l1': 61, 'dropout_l1': 0.4466833484599552, 'n_units_l2': 7, 'dropout_l2': 0.40061080042009867, 'optimizer': 'SGD', 'lr': 4.635993741452686e-05, 'l2': 7.772246159031267e-05}. Best is trial 3 with value: 0.255625.\n",
      "[I 2025-01-03 20:04:20,092] Trial 5 pruned. \n",
      "[I 2025-01-03 20:04:20,182] Trial 6 pruned. \n",
      "[I 2025-01-03 20:04:20,361] Trial 7 pruned. \n",
      "[I 2025-01-03 20:04:20,465] Trial 8 pruned. \n",
      "[I 2025-01-03 20:04:20,614] Trial 9 pruned. \n",
      "[I 2025-01-03 20:04:20,767] Trial 10 pruned. \n",
      "[I 2025-01-03 20:04:20,951] Trial 11 pruned. \n",
      "[I 2025-01-03 20:04:21,167] Trial 12 pruned. \n",
      "[I 2025-01-03 20:04:21,340] Trial 13 pruned. \n",
      "[I 2025-01-03 20:04:21,977] Trial 14 finished with value: 0.25 and parameters: {'n_layers': 1, 'n_units_l0': 24, 'dropout_l0': 0.39465130408406424, 'optimizer': 'SGD', 'lr': 0.0035563409123146443, 'l2': 0.9679960651870303}. Best is trial 3 with value: 0.255625.\n",
      "[I 2025-01-03 20:04:22,058] Trial 15 pruned. \n",
      "[I 2025-01-03 20:04:22,668] Trial 16 finished with value: 0.32875 and parameters: {'n_layers': 1, 'n_units_l0': 45, 'dropout_l0': 0.38905672321847234, 'optimizer': 'SGD', 'lr': 0.0024149351022959907, 'l2': 0.21012223342952155}. Best is trial 16 with value: 0.32875.\n",
      "[I 2025-01-03 20:04:22,764] Trial 17 pruned. \n",
      "[I 2025-01-03 20:04:22,840] Trial 18 pruned. \n",
      "[I 2025-01-03 20:04:22,937] Trial 19 pruned. \n",
      "[I 2025-01-03 20:04:23,074] Trial 20 pruned. \n",
      "[I 2025-01-03 20:04:23,157] Trial 21 pruned. \n",
      "[I 2025-01-03 20:04:23,284] Trial 22 pruned. \n",
      "[I 2025-01-03 20:04:23,364] Trial 23 pruned. \n",
      "[I 2025-01-03 20:04:23,430] Trial 24 pruned. \n",
      "[I 2025-01-03 20:04:23,656] Trial 25 pruned. \n",
      "[I 2025-01-03 20:04:23,738] Trial 26 pruned. \n",
      "[I 2025-01-03 20:04:23,896] Trial 27 pruned. \n",
      "[I 2025-01-03 20:04:23,978] Trial 28 pruned. \n",
      "[I 2025-01-03 20:04:24,533] Trial 29 finished with value: 0.27125 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'dropout_l0': 0.4643395937003571, 'optimizer': 'RMSprop', 'lr': 0.0008821171745469402, 'l2': 0.01034778928072858}. Best is trial 16 with value: 0.32875.\n",
      "[I 2025-01-03 20:04:25,116] Trial 30 finished with value: 0.170625 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'dropout_l0': 0.4550555648051986, 'optimizer': 'RMSprop', 'lr': 0.00025281250009469476, 'l2': 0.012877809477826968}. Best is trial 16 with value: 0.32875.\n",
      "[I 2025-01-03 20:04:25,197] Trial 31 pruned. \n",
      "[I 2025-01-03 20:04:25,275] Trial 32 pruned. \n",
      "[I 2025-01-03 20:04:25,357] Trial 33 pruned. \n",
      "[I 2025-01-03 20:04:26,003] Trial 34 finished with value: 0.201875 and parameters: {'n_layers': 1, 'n_units_l0': 26, 'dropout_l0': 0.46845261751726386, 'optimizer': 'SGD', 'lr': 0.0036156844428126625, 'l2': 0.0031183493304606062}. Best is trial 16 with value: 0.32875.\n",
      "[I 2025-01-03 20:04:26,637] Trial 35 finished with value: 0.196875 and parameters: {'n_layers': 1, 'n_units_l0': 39, 'dropout_l0': 0.3871928604558151, 'optimizer': 'RMSprop', 'lr': 0.0020763578540849027, 'l2': 0.21117810735184586}. Best is trial 16 with value: 0.32875.\n",
      "[I 2025-01-03 20:04:26,712] Trial 36 pruned. \n",
      "[I 2025-01-03 20:04:26,804] Trial 37 pruned. \n",
      "[I 2025-01-03 20:04:26,871] Trial 38 pruned. \n",
      "[I 2025-01-03 20:04:27,452] Trial 39 finished with value: 0.386875 and parameters: {'n_layers': 1, 'n_units_l0': 34, 'dropout_l0': 0.36045376214486347, 'optimizer': 'RMSprop', 'lr': 0.00044461538587087273, 'l2': 0.001919705397380416}. Best is trial 39 with value: 0.386875.\n",
      "[I 2025-01-03 20:04:27,561] Trial 40 pruned. \n",
      "[I 2025-01-03 20:04:27,664] Trial 41 pruned. \n",
      "[I 2025-01-03 20:04:28,278] Trial 42 finished with value: 0.3075 and parameters: {'n_layers': 1, 'n_units_l0': 27, 'dropout_l0': 0.3334703850751547, 'optimizer': 'RMSprop', 'lr': 0.0014773520155932887, 'l2': 0.0006285812092993639}. Best is trial 39 with value: 0.386875.\n",
      "[I 2025-01-03 20:04:28,379] Trial 43 pruned. \n",
      "[I 2025-01-03 20:04:28,473] Trial 44 pruned. \n",
      "[I 2025-01-03 20:04:28,544] Trial 45 pruned. \n",
      "[I 2025-01-03 20:04:28,645] Trial 46 pruned. \n",
      "[I 2025-01-03 20:04:28,778] Trial 47 pruned. \n",
      "[I 2025-01-03 20:04:28,860] Trial 48 pruned. \n",
      "[I 2025-01-03 20:04:28,961] Trial 49 pruned. \n",
      "[I 2025-01-03 20:04:29,043] Trial 50 pruned. \n",
      "[I 2025-01-03 20:04:29,127] Trial 51 pruned. \n",
      "[I 2025-01-03 20:04:29,210] Trial 52 pruned. \n",
      "[I 2025-01-03 20:04:29,293] Trial 53 pruned. \n",
      "[I 2025-01-03 20:04:29,393] Trial 54 pruned. \n",
      "[I 2025-01-03 20:04:29,476] Trial 55 pruned. \n",
      "[I 2025-01-03 20:04:29,560] Trial 56 pruned. \n",
      "[I 2025-01-03 20:04:29,651] Trial 57 pruned. \n",
      "[I 2025-01-03 20:04:29,727] Trial 58 pruned. \n",
      "[I 2025-01-03 20:04:29,827] Trial 59 pruned. \n",
      "[I 2025-01-03 20:04:29,926] Trial 60 pruned. \n",
      "[I 2025-01-03 20:04:30,009] Trial 61 pruned. \n",
      "[I 2025-01-03 20:04:30,093] Trial 62 pruned. \n",
      "[I 2025-01-03 20:04:30,261] Trial 63 pruned. \n",
      "[I 2025-01-03 20:04:30,358] Trial 64 pruned. \n",
      "[I 2025-01-03 20:04:30,442] Trial 65 pruned. \n",
      "[I 2025-01-03 20:04:30,541] Trial 66 pruned. \n",
      "[I 2025-01-03 20:04:30,626] Trial 67 pruned. \n",
      "[I 2025-01-03 20:04:30,725] Trial 68 pruned. \n",
      "[I 2025-01-03 20:04:30,828] Trial 69 pruned. \n",
      "[I 2025-01-03 20:04:32,018] Trial 70 finished with value: 0.3075 and parameters: {'n_layers': 1, 'n_units_l0': 62, 'dropout_l0': 0.34916095307191575, 'optimizer': 'RMSprop', 'lr': 0.0002839077686578609, 'l2': 0.025228396073092643}. Best is trial 39 with value: 0.386875.\n",
      "[I 2025-01-03 20:04:32,142] Trial 71 pruned. \n",
      "[I 2025-01-03 20:04:32,277] Trial 72 pruned. \n",
      "[I 2025-01-03 20:04:32,428] Trial 73 pruned. \n",
      "[I 2025-01-03 20:04:33,346] Trial 74 finished with value: 0.289375 and parameters: {'n_layers': 1, 'n_units_l0': 59, 'dropout_l0': 0.36675895984456164, 'optimizer': 'RMSprop', 'lr': 0.0037667575431992186, 'l2': 0.03935190536981347}. Best is trial 39 with value: 0.386875.\n",
      "[I 2025-01-03 20:04:33,538] Trial 75 pruned. \n",
      "[I 2025-01-03 20:04:34,290] Trial 76 finished with value: 0.27125 and parameters: {'n_layers': 1, 'n_units_l0': 55, 'dropout_l0': 0.3857326819524058, 'optimizer': 'RMSprop', 'lr': 0.002731050762690147, 'l2': 0.6080819668392748}. Best is trial 39 with value: 0.386875.\n",
      "[I 2025-01-03 20:04:34,386] Trial 77 pruned. \n",
      "[I 2025-01-03 20:04:34,474] Trial 78 pruned. \n",
      "[I 2025-01-03 20:04:34,556] Trial 79 pruned. \n",
      "[I 2025-01-03 20:04:34,655] Trial 80 pruned. \n",
      "[I 2025-01-03 20:04:34,741] Trial 81 pruned. \n",
      "[I 2025-01-03 20:04:34,824] Trial 82 pruned. \n",
      "[I 2025-01-03 20:04:34,923] Trial 83 pruned. \n",
      "[I 2025-01-03 20:04:35,017] Trial 84 pruned. \n",
      "[I 2025-01-03 20:04:35,096] Trial 85 pruned. \n",
      "[I 2025-01-03 20:04:35,168] Trial 86 pruned. \n",
      "[I 2025-01-03 20:04:35,269] Trial 87 pruned. \n",
      "[I 2025-01-03 20:04:35,339] Trial 88 pruned. \n",
      "[I 2025-01-03 20:04:35,406] Trial 89 pruned. \n",
      "[I 2025-01-03 20:04:35,502] Trial 90 pruned. \n",
      "[I 2025-01-03 20:04:35,556] Trial 91 pruned. \n",
      "[I 2025-01-03 20:04:35,639] Trial 92 pruned. \n",
      "[I 2025-01-03 20:04:35,723] Trial 93 pruned. \n",
      "[I 2025-01-03 20:04:35,806] Trial 94 pruned. \n",
      "[I 2025-01-03 20:04:35,890] Trial 95 pruned. \n",
      "[I 2025-01-03 20:04:35,973] Trial 96 pruned. \n",
      "[I 2025-01-03 20:04:36,039] Trial 97 pruned. \n",
      "[I 2025-01-03 20:04:36,295] Trial 98 pruned. \n",
      "[I 2025-01-03 20:04:36,373] Trial 99 pruned. \n",
      "[I 2025-01-03 20:04:36,460] Trial 100 pruned. \n",
      "[I 2025-01-03 20:04:36,566] Trial 101 pruned. \n",
      "[I 2025-01-03 20:04:36,690] Trial 102 pruned. \n",
      "[I 2025-01-03 20:04:36,790] Trial 103 pruned. \n",
      "[I 2025-01-03 20:04:36,900] Trial 104 pruned. \n",
      "[I 2025-01-03 20:04:36,970] Trial 105 pruned. \n",
      "[I 2025-01-03 20:04:37,054] Trial 106 pruned. \n",
      "[I 2025-01-03 20:04:37,153] Trial 107 pruned. \n",
      "[I 2025-01-03 20:04:37,253] Trial 108 pruned. \n",
      "[I 2025-01-03 20:04:37,323] Trial 109 pruned. \n",
      "[I 2025-01-03 20:04:37,388] Trial 110 pruned. \n",
      "[I 2025-01-03 20:04:37,508] Trial 111 pruned. \n",
      "[I 2025-01-03 20:04:37,598] Trial 112 pruned. \n",
      "[I 2025-01-03 20:04:37,670] Trial 113 pruned. \n",
      "[I 2025-01-03 20:04:37,786] Trial 114 pruned. \n",
      "[I 2025-01-03 20:04:37,854] Trial 115 pruned. \n",
      "[I 2025-01-03 20:04:37,971] Trial 116 pruned. \n",
      "[I 2025-01-03 20:04:38,037] Trial 117 pruned. \n",
      "[I 2025-01-03 20:04:38,122] Trial 118 pruned. \n",
      "[I 2025-01-03 20:04:38,187] Trial 119 pruned. \n",
      "[I 2025-01-03 20:04:38,288] Trial 120 pruned. \n",
      "[I 2025-01-03 20:04:38,372] Trial 121 pruned. \n",
      "[I 2025-01-03 20:04:38,455] Trial 122 pruned. \n",
      "[I 2025-01-03 20:04:38,525] Trial 123 pruned. \n",
      "[I 2025-01-03 20:04:38,603] Trial 124 pruned. \n",
      "[I 2025-01-03 20:04:38,672] Trial 125 pruned. \n",
      "[I 2025-01-03 20:04:38,737] Trial 126 pruned. \n",
      "[I 2025-01-03 20:04:38,804] Trial 127 pruned. \n",
      "[I 2025-01-03 20:04:39,425] Trial 128 finished with value: 0.221875 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'dropout_l0': 0.34952053335909816, 'optimizer': 'SGD', 'lr': 7.84070585813428e-05, 'l2': 0.9831083978251893}. Best is trial 39 with value: 0.386875.\n",
      "[I 2025-01-03 20:04:39,504] Trial 129 pruned. \n",
      "[I 2025-01-03 20:04:39,571] Trial 130 pruned. \n",
      "[I 2025-01-03 20:04:39,654] Trial 131 pruned. \n",
      "[I 2025-01-03 20:04:39,743] Trial 132 pruned. \n",
      "[I 2025-01-03 20:04:39,803] Trial 133 pruned. \n",
      "[I 2025-01-03 20:04:39,896] Trial 134 pruned. \n",
      "[I 2025-01-03 20:04:39,990] Trial 135 pruned. \n",
      "[I 2025-01-03 20:04:40,519] Trial 136 finished with value: 0.36625 and parameters: {'n_layers': 1, 'n_units_l0': 53, 'dropout_l0': 0.45120379289335, 'optimizer': 'SGD', 'lr': 0.0018963306714441066, 'l2': 0.0002724305843404301}. Best is trial 39 with value: 0.386875.\n",
      "[I 2025-01-03 20:04:40,601] Trial 137 pruned. \n",
      "[I 2025-01-03 20:04:40,686] Trial 138 pruned. \n",
      "[I 2025-01-03 20:04:40,780] Trial 139 pruned. \n",
      "[I 2025-01-03 20:04:40,882] Trial 140 pruned. \n",
      "[I 2025-01-03 20:04:41,036] Trial 141 pruned. \n",
      "[I 2025-01-03 20:04:41,119] Trial 142 pruned. \n",
      "[I 2025-01-03 20:04:41,186] Trial 143 pruned. \n",
      "[I 2025-01-03 20:04:41,268] Trial 144 pruned. \n",
      "[I 2025-01-03 20:04:41,351] Trial 145 pruned. \n",
      "[I 2025-01-03 20:04:41,417] Trial 146 pruned. \n",
      "[I 2025-01-03 20:04:41,485] Trial 147 pruned. \n",
      "[I 2025-01-03 20:04:41,552] Trial 148 pruned. \n",
      "[I 2025-01-03 20:04:41,628] Trial 149 pruned. \n",
      "[I 2025-01-03 20:04:41,715] Trial 150 pruned. \n",
      "[I 2025-01-03 20:04:41,819] Trial 151 pruned. \n",
      "[I 2025-01-03 20:04:41,948] Trial 152 pruned. \n",
      "[I 2025-01-03 20:04:42,051] Trial 153 pruned. \n",
      "[I 2025-01-03 20:04:42,165] Trial 154 pruned. \n",
      "[I 2025-01-03 20:04:42,252] Trial 155 pruned. \n",
      "[I 2025-01-03 20:04:42,352] Trial 156 pruned. \n",
      "[I 2025-01-03 20:04:42,432] Trial 157 pruned. \n",
      "[I 2025-01-03 20:04:42,535] Trial 158 pruned. \n",
      "[I 2025-01-03 20:04:42,616] Trial 159 pruned. \n",
      "[I 2025-01-03 20:04:42,685] Trial 160 pruned. \n",
      "[I 2025-01-03 20:04:42,769] Trial 161 pruned. \n",
      "[I 2025-01-03 20:04:42,885] Trial 162 pruned. \n",
      "[I 2025-01-03 20:04:42,987] Trial 163 pruned. \n",
      "[I 2025-01-03 20:04:43,088] Trial 164 pruned. \n",
      "[I 2025-01-03 20:04:43,187] Trial 165 pruned. \n",
      "[I 2025-01-03 20:04:43,811] Trial 166 finished with value: 0.393125 and parameters: {'n_layers': 1, 'n_units_l0': 59, 'dropout_l0': 0.4660135180154144, 'optimizer': 'SGD', 'lr': 0.002427468012008151, 'l2': 0.4322729899271826}. Best is trial 166 with value: 0.393125.\n",
      "[I 2025-01-03 20:04:43,899] Trial 167 pruned. \n",
      "[I 2025-01-03 20:04:44,501] Trial 168 finished with value: 0.3475 and parameters: {'n_layers': 1, 'n_units_l0': 67, 'dropout_l0': 0.4434949986891399, 'optimizer': 'SGD', 'lr': 0.0025461082231963052, 'l2': 0.38018597940829546}. Best is trial 166 with value: 0.393125.\n",
      "[I 2025-01-03 20:04:45,096] Trial 169 finished with value: 0.3725 and parameters: {'n_layers': 1, 'n_units_l0': 68, 'dropout_l0': 0.4366977418098817, 'optimizer': 'SGD', 'lr': 0.0024615220299874317, 'l2': 0.42907462034862254}. Best is trial 166 with value: 0.393125.\n",
      "[I 2025-01-03 20:04:45,168] Trial 170 pruned. \n",
      "[I 2025-01-03 20:04:45,241] Trial 171 pruned. \n",
      "[I 2025-01-03 20:04:45,313] Trial 172 pruned. \n",
      "[I 2025-01-03 20:04:45,917] Trial 173 finished with value: 0.409375 and parameters: {'n_layers': 1, 'n_units_l0': 83, 'dropout_l0': 0.4585179166506747, 'optimizer': 'SGD', 'lr': 0.0027685754134282496, 'l2': 0.6364302300030601}. Best is trial 173 with value: 0.409375.\n",
      "[I 2025-01-03 20:04:46,000] Trial 174 pruned. \n",
      "[I 2025-01-03 20:04:46,100] Trial 175 pruned. \n",
      "[I 2025-01-03 20:04:46,182] Trial 176 pruned. \n",
      "[I 2025-01-03 20:04:46,683] Trial 177 finished with value: 0.415625 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'dropout_l0': 0.47415030531896707, 'optimizer': 'SGD', 'lr': 0.002960084931415181, 'l2': 0.7191175002864437}. Best is trial 177 with value: 0.415625.\n",
      "[I 2025-01-03 20:04:46,767] Trial 178 pruned. \n",
      "[I 2025-01-03 20:04:46,898] Trial 179 pruned. \n",
      "[I 2025-01-03 20:04:47,903] Trial 180 finished with value: 0.376875 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.45440422218452076, 'optimizer': 'SGD', 'lr': 0.0033339166012331446, 'l2': 0.3728761860447452}. Best is trial 177 with value: 0.415625.\n",
      "[I 2025-01-03 20:04:48,167] Trial 181 pruned. \n",
      "[I 2025-01-03 20:04:48,302] Trial 182 pruned. \n",
      "[I 2025-01-03 20:04:49,024] Trial 183 finished with value: 0.47125 and parameters: {'n_layers': 1, 'n_units_l0': 90, 'dropout_l0': 0.4801244864190618, 'optimizer': 'SGD', 'lr': 0.002455759433335553, 'l2': 0.6012728116515451}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:49,601] Trial 184 finished with value: 0.39625 and parameters: {'n_layers': 1, 'n_units_l0': 90, 'dropout_l0': 0.48443881907844916, 'optimizer': 'SGD', 'lr': 0.0025010253428320198, 'l2': 0.6424565985408777}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:49,700] Trial 185 pruned. \n",
      "[I 2025-01-03 20:04:50,363] Trial 186 finished with value: 0.32125 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.49239148947507894, 'optimizer': 'SGD', 'lr': 0.002977456977452316, 'l2': 0.5303175090547884}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:50,447] Trial 187 pruned. \n",
      "[I 2025-01-03 20:04:51,049] Trial 188 finished with value: 0.42125 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.48875640723253755, 'optimizer': 'SGD', 'lr': 0.002694444501511025, 'l2': 0.25778278168535246}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:51,815] Trial 189 finished with value: 0.42625 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.48587483835244966, 'optimizer': 'SGD', 'lr': 0.0025431553562496353, 'l2': 0.2392907745103125}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:52,451] Trial 190 finished with value: 0.40625 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.48523010346236023, 'optimizer': 'SGD', 'lr': 0.0027633955618692405, 'l2': 0.15533533809638306}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:53,077] Trial 191 finished with value: 0.400625 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.486540282982805, 'optimizer': 'SGD', 'lr': 0.002328759324616742, 'l2': 0.15317969145558188}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:53,595] Trial 192 finished with value: 0.409375 and parameters: {'n_layers': 1, 'n_units_l0': 91, 'dropout_l0': 0.48799303719422, 'optimizer': 'SGD', 'lr': 0.002486238082032282, 'l2': 0.1781752088283809}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:53,684] Trial 193 pruned. \n",
      "[I 2025-01-03 20:04:53,745] Trial 194 pruned. \n",
      "[I 2025-01-03 20:04:53,840] Trial 195 pruned. \n",
      "[I 2025-01-03 20:04:53,911] Trial 196 pruned. \n",
      "[I 2025-01-03 20:04:54,564] Trial 197 finished with value: 0.4475 and parameters: {'n_layers': 1, 'n_units_l0': 100, 'dropout_l0': 0.4833640814847387, 'optimizer': 'SGD', 'lr': 0.001966925590512037, 'l2': 0.28494801667491576}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:54,643] Trial 198 pruned. \n",
      "[I 2025-01-03 20:04:55,221] Trial 199 finished with value: 0.44875 and parameters: {'n_layers': 1, 'n_units_l0': 102, 'dropout_l0': 0.4915002695924287, 'optimizer': 'SGD', 'lr': 0.0019428683285601365, 'l2': 0.23608915913797004}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:55,308] Trial 200 pruned. \n",
      "[I 2025-01-03 20:04:55,392] Trial 201 pruned. \n",
      "[I 2025-01-03 20:04:55,963] Trial 202 finished with value: 0.38125 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.4863870071660935, 'optimizer': 'SGD', 'lr': 0.002684828281888761, 'l2': 0.28181307120374843}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:56,633] Trial 203 finished with value: 0.41375 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.4898687032651155, 'optimizer': 'SGD', 'lr': 0.002727428415427206, 'l2': 0.2983696179895427}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:56,709] Trial 204 pruned. \n",
      "[I 2025-01-03 20:04:57,344] Trial 205 finished with value: 0.39625 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.4843216790779068, 'optimizer': 'SGD', 'lr': 0.0025803627924193134, 'l2': 0.34385616901602}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:57,425] Trial 206 pruned. \n",
      "[I 2025-01-03 20:04:57,528] Trial 207 pruned. \n",
      "[I 2025-01-03 20:04:57,624] Trial 208 pruned. \n",
      "[I 2025-01-03 20:04:57,744] Trial 209 pruned. \n",
      "[I 2025-01-03 20:04:57,833] Trial 210 pruned. \n",
      "[I 2025-01-03 20:04:57,908] Trial 211 pruned. \n",
      "[I 2025-01-03 20:04:57,990] Trial 212 pruned. \n",
      "[I 2025-01-03 20:04:58,587] Trial 213 finished with value: 0.37875 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.4755780619169671, 'optimizer': 'SGD', 'lr': 0.004040737542397949, 'l2': 0.2483644686033043}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:58,756] Trial 214 pruned. \n",
      "[I 2025-01-03 20:04:58,846] Trial 215 pruned. \n",
      "[I 2025-01-03 20:04:59,390] Trial 216 finished with value: 0.390625 and parameters: {'n_layers': 1, 'n_units_l0': 82, 'dropout_l0': 0.46906262595654913, 'optimizer': 'SGD', 'lr': 0.00335166209689081, 'l2': 0.18637885122919326}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:04:59,584] Trial 217 pruned. \n",
      "[I 2025-01-03 20:04:59,677] Trial 218 pruned. \n",
      "[I 2025-01-03 20:04:59,758] Trial 219 pruned. \n",
      "[I 2025-01-03 20:04:59,953] Trial 220 pruned. \n",
      "[I 2025-01-03 20:05:00,047] Trial 221 pruned. \n",
      "[I 2025-01-03 20:05:00,123] Trial 222 pruned. \n",
      "[I 2025-01-03 20:05:00,206] Trial 223 pruned. \n",
      "[I 2025-01-03 20:05:00,304] Trial 224 pruned. \n",
      "[I 2025-01-03 20:05:00,374] Trial 225 pruned. \n",
      "[I 2025-01-03 20:05:01,051] Trial 226 finished with value: 0.349375 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.4632096964196334, 'optimizer': 'SGD', 'lr': 0.004152628540661531, 'l2': 0.10333656991048465}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:01,138] Trial 227 pruned. \n",
      "[I 2025-01-03 20:05:01,221] Trial 228 pruned. \n",
      "[I 2025-01-03 20:05:01,304] Trial 229 pruned. \n",
      "[I 2025-01-03 20:05:01,388] Trial 230 pruned. \n",
      "[I 2025-01-03 20:05:01,995] Trial 231 finished with value: 0.465 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.48833428358223113, 'optimizer': 'SGD', 'lr': 0.0025375610095447016, 'l2': 0.18441387367660456}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:02,071] Trial 232 pruned. \n",
      "[I 2025-01-03 20:05:02,292] Trial 233 pruned. \n",
      "[I 2025-01-03 20:05:02,405] Trial 234 pruned. \n",
      "[I 2025-01-03 20:05:02,508] Trial 235 pruned. \n",
      "[I 2025-01-03 20:05:03,573] Trial 236 finished with value: 0.445625 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.4781899769216611, 'optimizer': 'SGD', 'lr': 0.0026079886730657736, 'l2': 0.23699131111802135}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:03,722] Trial 237 pruned. \n",
      "[I 2025-01-03 20:05:03,872] Trial 238 pruned. \n",
      "[I 2025-01-03 20:05:04,033] Trial 239 pruned. \n",
      "[I 2025-01-03 20:05:04,226] Trial 240 pruned. \n",
      "[I 2025-01-03 20:05:04,521] Trial 241 pruned. \n",
      "[I 2025-01-03 20:05:04,688] Trial 242 pruned. \n",
      "[I 2025-01-03 20:05:05,038] Trial 243 pruned. \n",
      "[I 2025-01-03 20:05:05,187] Trial 244 pruned. \n",
      "[I 2025-01-03 20:05:05,269] Trial 245 pruned. \n",
      "[I 2025-01-03 20:05:05,936] Trial 246 finished with value: 0.36 and parameters: {'n_layers': 1, 'n_units_l0': 89, 'dropout_l0': 0.4550071971336448, 'optimizer': 'SGD', 'lr': 0.002280403201448789, 'l2': 0.427582623885122}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:06,018] Trial 247 pruned. \n",
      "[I 2025-01-03 20:05:06,102] Trial 248 pruned. \n",
      "[I 2025-01-03 20:05:06,803] Trial 249 finished with value: 0.4 and parameters: {'n_layers': 1, 'n_units_l0': 83, 'dropout_l0': 0.4834118395032791, 'optimizer': 'SGD', 'lr': 0.003051081630336059, 'l2': 0.46910485797160867}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:06,886] Trial 250 pruned. \n",
      "[I 2025-01-03 20:05:06,967] Trial 251 pruned. \n",
      "[I 2025-01-03 20:05:07,052] Trial 252 pruned. \n",
      "[I 2025-01-03 20:05:07,134] Trial 253 pruned. \n",
      "[I 2025-01-03 20:05:07,218] Trial 254 pruned. \n",
      "[I 2025-01-03 20:05:07,302] Trial 255 pruned. \n",
      "[I 2025-01-03 20:05:07,384] Trial 256 pruned. \n",
      "[I 2025-01-03 20:05:07,977] Trial 257 finished with value: 0.44 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.49539678564304507, 'optimizer': 'SGD', 'lr': 0.002777133627995251, 'l2': 0.2510488757486387}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:08,565] Trial 258 finished with value: 0.408125 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.4971543549702979, 'optimizer': 'SGD', 'lr': 0.0031290174933214614, 'l2': 0.2586177210858619}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:08,653] Trial 259 pruned. \n",
      "[I 2025-01-03 20:05:08,885] Trial 260 pruned. \n",
      "[I 2025-01-03 20:05:09,035] Trial 261 pruned. \n",
      "[I 2025-01-03 20:05:09,653] Trial 262 finished with value: 0.435625 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.4951113600979898, 'optimizer': 'SGD', 'lr': 0.0027181859667759884, 'l2': 0.29073640805852713}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:09,734] Trial 263 pruned. \n",
      "[I 2025-01-03 20:05:09,816] Trial 264 pruned. \n",
      "[I 2025-01-03 20:05:09,913] Trial 265 pruned. \n",
      "[I 2025-01-03 20:05:09,999] Trial 266 pruned. \n",
      "[I 2025-01-03 20:05:10,067] Trial 267 pruned. \n",
      "[I 2025-01-03 20:05:10,153] Trial 268 pruned. \n",
      "[I 2025-01-03 20:05:10,699] Trial 269 finished with value: 0.419375 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.4894084441504994, 'optimizer': 'SGD', 'lr': 0.002713477163376228, 'l2': 0.348659489535444}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:11,355] Trial 270 finished with value: 0.444375 and parameters: {'n_layers': 1, 'n_units_l0': 104, 'dropout_l0': 0.4892541741027145, 'optimizer': 'SGD', 'lr': 0.002603574358123052, 'l2': 0.832478436501889}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:11,889] Trial 271 finished with value: 0.40125 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.49467480320334056, 'optimizer': 'SGD', 'lr': 0.0025498507145358565, 'l2': 0.839041401035994}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:11,965] Trial 272 pruned. \n",
      "[I 2025-01-03 20:05:12,060] Trial 273 pruned. \n",
      "[I 2025-01-03 20:05:12,131] Trial 274 pruned. \n",
      "[I 2025-01-03 20:05:12,698] Trial 275 finished with value: 0.37625 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.4963345326511762, 'optimizer': 'SGD', 'lr': 0.002212924892438314, 'l2': 0.6367585148547734}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:12,783] Trial 276 pruned. \n",
      "[I 2025-01-03 20:05:12,865] Trial 277 pruned. \n",
      "[I 2025-01-03 20:05:13,075] Trial 278 pruned. \n",
      "[I 2025-01-03 20:05:13,148] Trial 279 pruned. \n",
      "[I 2025-01-03 20:05:13,231] Trial 280 pruned. \n",
      "[I 2025-01-03 20:05:13,298] Trial 281 pruned. \n",
      "[I 2025-01-03 20:05:13,382] Trial 282 pruned. \n",
      "[I 2025-01-03 20:05:13,465] Trial 283 pruned. \n",
      "[I 2025-01-03 20:05:13,547] Trial 284 pruned. \n",
      "[I 2025-01-03 20:05:13,636] Trial 285 pruned. \n",
      "[I 2025-01-03 20:05:13,714] Trial 286 pruned. \n",
      "[I 2025-01-03 20:05:13,797] Trial 287 pruned. \n",
      "[I 2025-01-03 20:05:13,896] Trial 288 pruned. \n",
      "[I 2025-01-03 20:05:13,965] Trial 289 pruned. \n",
      "[I 2025-01-03 20:05:14,047] Trial 290 pruned. \n",
      "[I 2025-01-03 20:05:14,595] Trial 291 finished with value: 0.400625 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.4823647889661654, 'optimizer': 'SGD', 'lr': 0.00250120960649391, 'l2': 0.1894261287572215}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:14,682] Trial 292 pruned. \n",
      "[I 2025-01-03 20:05:14,779] Trial 293 pruned. \n",
      "[I 2025-01-03 20:05:15,408] Trial 294 finished with value: 0.410625 and parameters: {'n_layers': 1, 'n_units_l0': 87, 'dropout_l0': 0.4734653727888565, 'optimizer': 'SGD', 'lr': 0.0025020822138407885, 'l2': 0.19785779820917687}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:15,480] Trial 295 pruned. \n",
      "[I 2025-01-03 20:05:15,564] Trial 296 pruned. \n",
      "[I 2025-01-03 20:05:15,646] Trial 297 pruned. \n",
      "[I 2025-01-03 20:05:15,731] Trial 298 pruned. \n",
      "[I 2025-01-03 20:05:16,330] Trial 299 finished with value: 0.4475 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.4840290935449745, 'optimizer': 'SGD', 'lr': 0.0022408987079127534, 'l2': 0.4951856483778387}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:16,413] Trial 300 pruned. \n",
      "[I 2025-01-03 20:05:16,507] Trial 301 pruned. \n",
      "[I 2025-01-03 20:05:17,046] Trial 302 finished with value: 0.40875 and parameters: {'n_layers': 1, 'n_units_l0': 93, 'dropout_l0': 0.48417799876222317, 'optimizer': 'SGD', 'lr': 0.0029192835659296143, 'l2': 0.13841853040513186}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:17,128] Trial 303 pruned. \n",
      "[I 2025-01-03 20:05:17,217] Trial 304 pruned. \n",
      "[I 2025-01-03 20:05:17,863] Trial 305 finished with value: 0.420625 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'dropout_l0': 0.48122035857023826, 'optimizer': 'SGD', 'lr': 0.0022336322902116817, 'l2': 0.1708383283547238}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:17,945] Trial 306 pruned. \n",
      "[I 2025-01-03 20:05:18,028] Trial 307 pruned. \n",
      "[I 2025-01-03 20:05:18,112] Trial 308 pruned. \n",
      "[I 2025-01-03 20:05:18,210] Trial 309 pruned. \n",
      "[I 2025-01-03 20:05:18,300] Trial 310 pruned. \n",
      "[I 2025-01-03 20:05:18,423] Trial 311 pruned. \n",
      "[I 2025-01-03 20:05:18,515] Trial 312 pruned. \n",
      "[I 2025-01-03 20:05:18,636] Trial 313 pruned. \n",
      "[I 2025-01-03 20:05:18,725] Trial 314 pruned. \n",
      "[I 2025-01-03 20:05:18,810] Trial 315 pruned. \n",
      "[I 2025-01-03 20:05:18,962] Trial 316 pruned. \n",
      "[I 2025-01-03 20:05:19,131] Trial 317 pruned. \n",
      "[I 2025-01-03 20:05:20,430] Trial 318 finished with value: 0.410625 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.471720206106679, 'optimizer': 'SGD', 'lr': 0.002675287389561424, 'l2': 0.293725764300782}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:20,594] Trial 319 pruned. \n",
      "[I 2025-01-03 20:05:20,728] Trial 320 pruned. \n",
      "[I 2025-01-03 20:05:20,894] Trial 321 pruned. \n",
      "[I 2025-01-03 20:05:21,031] Trial 322 pruned. \n",
      "[I 2025-01-03 20:05:21,143] Trial 323 pruned. \n",
      "[I 2025-01-03 20:05:21,248] Trial 324 pruned. \n",
      "[I 2025-01-03 20:05:21,341] Trial 325 pruned. \n",
      "[I 2025-01-03 20:05:21,464] Trial 326 pruned. \n",
      "[I 2025-01-03 20:05:22,143] Trial 327 finished with value: 0.41375 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.4829003583777983, 'optimizer': 'SGD', 'lr': 0.002853090835252675, 'l2': 0.21566960113765585}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:22,260] Trial 328 pruned. \n",
      "[I 2025-01-03 20:05:22,365] Trial 329 pruned. \n",
      "[I 2025-01-03 20:05:22,465] Trial 330 pruned. \n",
      "[I 2025-01-03 20:05:22,558] Trial 331 pruned. \n",
      "[I 2025-01-03 20:05:22,626] Trial 332 pruned. \n",
      "[I 2025-01-03 20:05:22,724] Trial 333 pruned. \n",
      "[I 2025-01-03 20:05:22,809] Trial 334 pruned. \n",
      "[I 2025-01-03 20:05:22,892] Trial 335 pruned. \n",
      "[I 2025-01-03 20:05:23,592] Trial 336 finished with value: 0.443125 and parameters: {'n_layers': 1, 'n_units_l0': 87, 'dropout_l0': 0.4736818681907707, 'optimizer': 'SGD', 'lr': 0.00244981266859439, 'l2': 0.224336868911924}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:23,693] Trial 337 pruned. \n",
      "[I 2025-01-03 20:05:23,805] Trial 338 pruned. \n",
      "[I 2025-01-03 20:05:24,094] Trial 339 pruned. \n",
      "[I 2025-01-03 20:05:24,193] Trial 340 pruned. \n",
      "[I 2025-01-03 20:05:24,426] Trial 341 pruned. \n",
      "[I 2025-01-03 20:05:24,508] Trial 342 pruned. \n",
      "[I 2025-01-03 20:05:24,609] Trial 343 pruned. \n",
      "[I 2025-01-03 20:05:25,211] Trial 344 finished with value: 0.41375 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.49559784062578605, 'optimizer': 'SGD', 'lr': 0.0027937710240738003, 'l2': 0.6345052270090455}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:25,302] Trial 345 pruned. \n",
      "[I 2025-01-03 20:05:25,373] Trial 346 pruned. \n",
      "[I 2025-01-03 20:05:25,477] Trial 347 pruned. \n",
      "[I 2025-01-03 20:05:25,556] Trial 348 pruned. \n",
      "[I 2025-01-03 20:05:25,640] Trial 349 pruned. \n",
      "[I 2025-01-03 20:05:26,324] Trial 350 finished with value: 0.430625 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.4778229850017142, 'optimizer': 'SGD', 'lr': 0.002230996786714548, 'l2': 0.4652126104137683}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:26,423] Trial 351 pruned. \n",
      "[I 2025-01-03 20:05:26,490] Trial 352 pruned. \n",
      "[I 2025-01-03 20:05:26,573] Trial 353 pruned. \n",
      "[I 2025-01-03 20:05:26,675] Trial 354 pruned. \n",
      "[I 2025-01-03 20:05:26,797] Trial 355 pruned. \n",
      "[I 2025-01-03 20:05:26,903] Trial 356 pruned. \n",
      "[I 2025-01-03 20:05:27,034] Trial 357 pruned. \n",
      "[I 2025-01-03 20:05:27,137] Trial 358 pruned. \n",
      "[I 2025-01-03 20:05:27,223] Trial 359 pruned. \n",
      "[I 2025-01-03 20:05:27,321] Trial 360 pruned. \n",
      "[I 2025-01-03 20:05:27,413] Trial 361 pruned. \n",
      "[I 2025-01-03 20:05:27,504] Trial 362 pruned. \n",
      "[I 2025-01-03 20:05:27,740] Trial 363 pruned. \n",
      "[I 2025-01-03 20:05:27,841] Trial 364 pruned. \n",
      "[I 2025-01-03 20:05:28,035] Trial 365 pruned. \n",
      "[I 2025-01-03 20:05:28,136] Trial 366 pruned. \n",
      "[I 2025-01-03 20:05:28,356] Trial 367 pruned. \n",
      "[I 2025-01-03 20:05:28,457] Trial 368 pruned. \n",
      "[I 2025-01-03 20:05:28,558] Trial 369 pruned. \n",
      "[I 2025-01-03 20:05:29,225] Trial 370 finished with value: 0.444375 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'dropout_l0': 0.4813486067631812, 'optimizer': 'SGD', 'lr': 0.0021591540028338095, 'l2': 0.24186756362116507}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:29,356] Trial 371 pruned. \n",
      "[I 2025-01-03 20:05:29,439] Trial 372 pruned. \n",
      "[I 2025-01-03 20:05:29,522] Trial 373 pruned. \n",
      "[I 2025-01-03 20:05:29,623] Trial 374 pruned. \n",
      "[I 2025-01-03 20:05:29,722] Trial 375 pruned. \n",
      "[I 2025-01-03 20:05:29,822] Trial 376 pruned. \n",
      "[I 2025-01-03 20:05:30,388] Trial 377 finished with value: 0.435 and parameters: {'n_layers': 1, 'n_units_l0': 123, 'dropout_l0': 0.4837012876057204, 'optimizer': 'SGD', 'lr': 0.002687814018753908, 'l2': 0.16177454803808972}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:30,485] Trial 378 pruned. \n",
      "[I 2025-01-03 20:05:30,574] Trial 379 pruned. \n",
      "[I 2025-01-03 20:05:30,672] Trial 380 pruned. \n",
      "[I 2025-01-03 20:05:30,855] Trial 381 pruned. \n",
      "[I 2025-01-03 20:05:30,953] Trial 382 pruned. \n",
      "[I 2025-01-03 20:05:31,054] Trial 383 pruned. \n",
      "[I 2025-01-03 20:05:31,151] Trial 384 pruned. \n",
      "[I 2025-01-03 20:05:31,237] Trial 385 pruned. \n",
      "[I 2025-01-03 20:05:31,335] Trial 386 pruned. \n",
      "[I 2025-01-03 20:05:31,438] Trial 387 pruned. \n",
      "[I 2025-01-03 20:05:31,555] Trial 388 pruned. \n",
      "[I 2025-01-03 20:05:31,658] Trial 389 pruned. \n",
      "[I 2025-01-03 20:05:31,755] Trial 390 pruned. \n",
      "[I 2025-01-03 20:05:31,855] Trial 391 pruned. \n",
      "[I 2025-01-03 20:05:31,971] Trial 392 pruned. \n",
      "[I 2025-01-03 20:05:32,107] Trial 393 pruned. \n",
      "[I 2025-01-03 20:05:32,288] Trial 394 pruned. \n",
      "[I 2025-01-03 20:05:32,389] Trial 395 pruned. \n",
      "[I 2025-01-03 20:05:32,488] Trial 396 pruned. \n",
      "[I 2025-01-03 20:05:32,625] Trial 397 pruned. \n",
      "[I 2025-01-03 20:05:32,733] Trial 398 pruned. \n",
      "[I 2025-01-03 20:05:32,844] Trial 399 pruned. \n",
      "[I 2025-01-03 20:05:32,955] Trial 400 pruned. \n",
      "[I 2025-01-03 20:05:33,076] Trial 401 pruned. \n",
      "[I 2025-01-03 20:05:33,187] Trial 402 pruned. \n",
      "[I 2025-01-03 20:05:33,286] Trial 403 pruned. \n",
      "[I 2025-01-03 20:05:33,388] Trial 404 pruned. \n",
      "[I 2025-01-03 20:05:33,505] Trial 405 pruned. \n",
      "[I 2025-01-03 20:05:33,622] Trial 406 pruned. \n",
      "[I 2025-01-03 20:05:34,404] Trial 407 finished with value: 0.43375 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.47743785904804853, 'optimizer': 'SGD', 'lr': 0.0024626291716789268, 'l2': 0.2423207548699104}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:34,522] Trial 408 pruned. \n",
      "[I 2025-01-03 20:05:34,735] Trial 409 pruned. \n",
      "[I 2025-01-03 20:05:35,905] Trial 410 finished with value: 0.4075 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.47736465241410536, 'optimizer': 'SGD', 'lr': 0.002347912512355176, 'l2': 0.32698756869993734}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:36,048] Trial 411 pruned. \n",
      "[I 2025-01-03 20:05:36,248] Trial 412 pruned. \n",
      "[I 2025-01-03 20:05:36,466] Trial 413 pruned. \n",
      "[I 2025-01-03 20:05:36,692] Trial 414 pruned. \n",
      "[I 2025-01-03 20:05:36,938] Trial 415 pruned. \n",
      "[I 2025-01-03 20:05:37,117] Trial 416 pruned. \n",
      "[I 2025-01-03 20:05:37,299] Trial 417 pruned. \n",
      "[I 2025-01-03 20:05:37,480] Trial 418 pruned. \n",
      "[I 2025-01-03 20:05:37,633] Trial 419 pruned. \n",
      "[I 2025-01-03 20:05:38,404] Trial 420 finished with value: 0.38625 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.4822566335329349, 'optimizer': 'SGD', 'lr': 0.0028219395757220936, 'l2': 0.8661921317596416}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:38,509] Trial 421 pruned. \n",
      "[I 2025-01-03 20:05:38,612] Trial 422 pruned. \n",
      "[I 2025-01-03 20:05:38,721] Trial 423 pruned. \n",
      "[I 2025-01-03 20:05:38,843] Trial 424 pruned. \n",
      "[I 2025-01-03 20:05:39,516] Trial 425 finished with value: 0.451875 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'dropout_l0': 0.4698875560059001, 'optimizer': 'SGD', 'lr': 0.0027318234828029773, 'l2': 0.20630308568231723}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:39,625] Trial 426 pruned. \n",
      "[I 2025-01-03 20:05:40,211] Trial 427 finished with value: 0.4275 and parameters: {'n_layers': 1, 'n_units_l0': 119, 'dropout_l0': 0.4843618113730864, 'optimizer': 'SGD', 'lr': 0.003022600550123413, 'l2': 0.11698314662682494}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:40,431] Trial 428 pruned. \n",
      "[I 2025-01-03 20:05:40,532] Trial 429 pruned. \n",
      "[I 2025-01-03 20:05:40,632] Trial 430 pruned. \n",
      "[I 2025-01-03 20:05:40,776] Trial 431 pruned. \n",
      "[I 2025-01-03 20:05:40,865] Trial 432 pruned. \n",
      "[I 2025-01-03 20:05:40,989] Trial 433 pruned. \n",
      "[I 2025-01-03 20:05:41,130] Trial 434 pruned. \n",
      "[I 2025-01-03 20:05:41,231] Trial 435 pruned. \n",
      "[I 2025-01-03 20:05:41,888] Trial 436 finished with value: 0.45875 and parameters: {'n_layers': 1, 'n_units_l0': 110, 'dropout_l0': 0.48989191218599976, 'optimizer': 'SGD', 'lr': 0.0023553018882408413, 'l2': 0.0756108995852836}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:42,291] Trial 437 pruned. \n",
      "[I 2025-01-03 20:05:42,461] Trial 438 pruned. \n",
      "[I 2025-01-03 20:05:42,702] Trial 439 pruned. \n",
      "[I 2025-01-03 20:05:42,827] Trial 440 pruned. \n",
      "[I 2025-01-03 20:05:42,932] Trial 441 pruned. \n",
      "[I 2025-01-03 20:05:43,042] Trial 442 pruned. \n",
      "[I 2025-01-03 20:05:43,894] Trial 443 finished with value: 0.42875 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.4888154203528713, 'optimizer': 'SGD', 'lr': 0.0023315236229230502, 'l2': 0.16223859829998974}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:44,001] Trial 444 pruned. \n",
      "[I 2025-01-03 20:05:44,107] Trial 445 pruned. \n",
      "[I 2025-01-03 20:05:44,289] Trial 446 pruned. \n",
      "[I 2025-01-03 20:05:44,367] Trial 447 pruned. \n",
      "[I 2025-01-03 20:05:44,463] Trial 448 pruned. \n",
      "[I 2025-01-03 20:05:44,542] Trial 449 pruned. \n",
      "[I 2025-01-03 20:05:44,635] Trial 450 pruned. \n",
      "[I 2025-01-03 20:05:44,711] Trial 451 pruned. \n",
      "[I 2025-01-03 20:05:44,807] Trial 452 pruned. \n",
      "[I 2025-01-03 20:05:44,889] Trial 453 pruned. \n",
      "[I 2025-01-03 20:05:44,967] Trial 454 pruned. \n",
      "[I 2025-01-03 20:05:45,059] Trial 455 pruned. \n",
      "[I 2025-01-03 20:05:45,154] Trial 456 pruned. \n",
      "[I 2025-01-03 20:05:45,243] Trial 457 pruned. \n",
      "[I 2025-01-03 20:05:45,338] Trial 458 pruned. \n",
      "[I 2025-01-03 20:05:45,902] Trial 459 finished with value: 0.42125 and parameters: {'n_layers': 1, 'n_units_l0': 103, 'dropout_l0': 0.4952097133580397, 'optimizer': 'SGD', 'lr': 0.0024658603077943523, 'l2': 0.34335255598790054}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:45,981] Trial 460 pruned. \n",
      "[I 2025-01-03 20:05:46,139] Trial 461 pruned. \n",
      "[I 2025-01-03 20:05:46,245] Trial 462 pruned. \n",
      "[I 2025-01-03 20:05:46,841] Trial 463 finished with value: 0.410625 and parameters: {'n_layers': 1, 'n_units_l0': 116, 'dropout_l0': 0.4906951049775695, 'optimizer': 'SGD', 'lr': 0.002414358449717869, 'l2': 0.2742374154094288}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:46,920] Trial 464 pruned. \n",
      "[I 2025-01-03 20:05:47,014] Trial 465 pruned. \n",
      "[I 2025-01-03 20:05:47,094] Trial 466 pruned. \n",
      "[I 2025-01-03 20:05:47,191] Trial 467 pruned. \n",
      "[I 2025-01-03 20:05:47,298] Trial 468 pruned. \n",
      "[I 2025-01-03 20:05:47,374] Trial 469 pruned. \n",
      "[I 2025-01-03 20:05:47,468] Trial 470 pruned. \n",
      "[I 2025-01-03 20:05:47,546] Trial 471 pruned. \n",
      "[I 2025-01-03 20:05:47,653] Trial 472 pruned. \n",
      "[I 2025-01-03 20:05:47,794] Trial 473 pruned. \n",
      "[I 2025-01-03 20:05:47,895] Trial 474 pruned. \n",
      "[I 2025-01-03 20:05:48,006] Trial 475 pruned. \n",
      "[I 2025-01-03 20:05:48,077] Trial 476 pruned. \n",
      "[I 2025-01-03 20:05:48,186] Trial 477 pruned. \n",
      "[I 2025-01-03 20:05:48,273] Trial 478 pruned. \n",
      "[I 2025-01-03 20:05:48,355] Trial 479 pruned. \n",
      "[I 2025-01-03 20:05:48,450] Trial 480 pruned. \n",
      "[I 2025-01-03 20:05:48,528] Trial 481 pruned. \n",
      "[I 2025-01-03 20:05:48,622] Trial 482 pruned. \n",
      "[I 2025-01-03 20:05:48,824] Trial 483 pruned. \n",
      "[I 2025-01-03 20:05:48,929] Trial 484 pruned. \n",
      "[I 2025-01-03 20:05:49,006] Trial 485 pruned. \n",
      "[I 2025-01-03 20:05:49,128] Trial 486 pruned. \n",
      "[I 2025-01-03 20:05:49,222] Trial 487 pruned. \n",
      "[I 2025-01-03 20:05:49,318] Trial 488 pruned. \n",
      "[I 2025-01-03 20:05:49,923] Trial 489 finished with value: 0.45375 and parameters: {'n_layers': 1, 'n_units_l0': 118, 'dropout_l0': 0.4922114770152788, 'optimizer': 'SGD', 'lr': 0.002574349827116058, 'l2': 0.39503166494532505}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:50,009] Trial 490 pruned. \n",
      "[I 2025-01-03 20:05:50,107] Trial 491 pruned. \n",
      "[I 2025-01-03 20:05:50,194] Trial 492 pruned. \n",
      "[I 2025-01-03 20:05:50,282] Trial 493 pruned. \n",
      "[I 2025-01-03 20:05:50,409] Trial 494 pruned. \n",
      "[I 2025-01-03 20:05:50,495] Trial 495 pruned. \n",
      "[I 2025-01-03 20:05:50,574] Trial 496 pruned. \n",
      "[I 2025-01-03 20:05:50,685] Trial 497 pruned. \n",
      "[I 2025-01-03 20:05:51,817] Trial 498 finished with value: 0.405 and parameters: {'n_layers': 1, 'n_units_l0': 122, 'dropout_l0': 0.49326996740598816, 'optimizer': 'SGD', 'lr': 0.0025275369431526132, 'l2': 0.35256855925217234}. Best is trial 183 with value: 0.47125.\n",
      "[I 2025-01-03 20:05:51,986] Trial 499 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  500\n",
      "  Number of pruned trials:  426\n",
      "  Number of complete trials:  74\n",
      "Best trial:\n",
      "  Value:  0.47125\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 90\n",
      "    dropout_l0: 0.4801244864190618\n",
      "    optimizer: SGD\n",
      "    lr: 0.002455759433335553\n",
      "    l2: 0.6012728116515451\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 #epochs are fixed to simplify the tuning\n",
    "\n",
    "#defining the hyperparameter space of the model hyperparameters\n",
    "def define_model(trial):\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3) #layers can take any number between 1 and 3\n",
    "    layers = []\n",
    "\n",
    "    in_features = num_features\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128) #number of unites/layer can take any number between 4 and 128\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5) #the dropoout probability can take any float number between 0.2 and 0.5\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, len(s_values)))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "#defining the hyperparameter space of the objective function hyperparameters\n",
    "def objective(trial):\n",
    "    \n",
    "    model = define_model(trial)\n",
    "\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    l2 = trial.suggest_float(\"l2\", 1e-5, 1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=l2)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            targets = targets - 1 #substracting one to be consistent with what Cross Entropy Loss in PyTorch expect\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(validation_data.X)\n",
    "            y_pred = torch.argmax(y_pred, dim=1).numpy() # Transformation of the dummy variable to the class index\n",
    "            y_true = validation_data.Y - 1\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        trial.report(acc, epoch)\n",
    "\n",
    "        #Pruning unpromising trials to save time\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return acc # returning the metric that direct the bayesian optimization\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\") #The metric is to be maximized\n",
    "    study.optimize(objective, n_trials=500) #The number of trials is 500\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1892b09a-39fa-4b46-9187-35aa4c6bd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with the best parameters on the training data\n",
    "#The corect way is to train on the training data including the validation data\n",
    "#But here I didn't include it for time reasons\n",
    "best_model = define_model(trial)\n",
    "best_optimizer = getattr(optim, trial.params[\"optimizer\"])(\n",
    "    best_model.parameters(),\n",
    "    lr=trial.params[\"lr\"],\n",
    "    weight_decay=trial.params[\"l2\"]\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_model.train()\n",
    "for inputs, targets in trainloader:\n",
    "    best_optimizer.zero_grad()\n",
    "    outputs = best_model(inputs)\n",
    "    targets = targets - 1 \n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    best_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e28d740-995b-4ad8-a95d-9d922de7170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.259\n"
     ]
    }
   ],
   "source": [
    "#evaluating on the test data gives 0.259, which show that the model perform slightly better than a uniform guesser because each class has the proportion 1/5 = 0.2\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(testing_data.X)\n",
    "    test_pred = torch.argmax(test_outputs, dim=1).numpy()\n",
    "    test_true = testing_data.Y - 1\n",
    "    test_accuracy = accuracy_score(test_true, test_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
