{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2c8e05-b210-4fe6-be58-4deca4b29d1d",
   "metadata": {},
   "source": [
    "# Classification of a vectors of random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295fb5d-ba9f-4156-8a1b-2e1005963dd7",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "For the demonstration, I choose to use synthetic data to simplify things and save time\n",
    "### Predictors and targets\n",
    "- The predictor $X$ is a 10-dimensional vector where the entries are comming from a normal distribution $N \\left( \\mu, \\sigma \\right)$\n",
    "I choose to fix $\\mu = 100$ and to have instances where $\\sigma \\in \\{1, 2, 3, 4, 5\\}$\n",
    "- So for a given instance, the predictor is $X$ and the target $Y = \\sigma$\n",
    "### Goal\n",
    "Our goal is to classify i.e. to predict the standard deviation $\\sigma$ based on the vector $X$\n",
    "### Approach\n",
    "- We split data into training, validation and test data\n",
    "- We use a feedforward neural network, there is no need to have a sequence-oriented model such as RNN, because the entries of the vector are independant\n",
    "- We choose to fix epochs in 10, and tune other hyperparameters using a the optuna framework, which uses a bayesian optimization approach. An approach that is similar to the popular idea in reinforecement learning, explore and exploit. So it explore the hyperparameter space in a non-exaustive way, but uses precious experiences to guide future explorations.\n",
    "- I have used the accuaracy metric as the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b7e4ec-e9a3-4fc3-b060-b150142812b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omarg\\anaconda3\\envs\\new\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65de784f-cf63-45ee-8711-ef3da68f64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = 10000 #number of instances\n",
    "num_features = 10 #number of features\n",
    "s_values = [1, 2, 3, 4, 5] #the classes, i.e. the standard deviation of the sampling distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbd626e-002b-4044-9893-693399e0e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2492ab-26f8-4559-8e01-dfbbc7e7a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data\n",
    "for _ in range(num_instances):\n",
    "    s = np.random.choice(s_values)\n",
    "    x = np.random.normal(loc=100, scale=s, size=num_features)#loc : mean, scale:standard deviation, size: the vector shape\n",
    "    y = s\n",
    "    X.append(x)\n",
    "    Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34eed5c2-ffa4-484c-ba69-c464f0469926",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26b37f3-f3b9-4877-8c4b-6e65c12e2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d9fbaf-fd00-47a0-8060-6adc62905719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.17638753 105.6857599   99.96593757 100.67336482  95.20160576\n",
      "   94.13332335 102.99837397 102.30989689 100.98484297  98.93804997]\n",
      " [101.68806758 104.83197281 107.31234839  98.59348049 102.86933762\n",
      "  103.01978111 104.49177709 101.95128366 100.80796518 105.82620846]\n",
      " [100.08504887 100.88202215 102.71374508 100.00107162  99.37302877\n",
      "  100.7600573  100.93900502  99.56885414 100.18623627 100.44885194]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129ded28-4292-473d-9547-1bb1a2a7af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4066b26-64ab-46dd-bffb-362840317ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For s = 1 --> 0.204\n",
      "For s = 2 --> 0.1981\n",
      "For s = 3 --> 0.1998\n",
      "For s = 4 --> 0.206\n",
      "For s = 5 --> 0.1921\n"
     ]
    }
   ],
   "source": [
    "# verifying if the resulting instances are balanced over classes\n",
    "for s in s_values:\n",
    "    print('For s =', s, '-->',len(Y[Y==s])/len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984d559b-5583-452b-adc6-defa357a83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting with making sure that the resulting splits have the same distribution as the original data\n",
    "# This is important especialy for the test data, so to be representative of real external data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49cb4369-9574-4ec3-8f56-d781a3b19bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For s = 1 --> 0.204\n",
      "For s = 2 --> 0.198125\n",
      "For s = 3 --> 0.19975\n",
      "For s = 4 --> 0.206\n",
      "For s = 5 --> 0.192125\n"
     ]
    }
   ],
   "source": [
    "# verifying again after splitting\n",
    "for s in s_values:\n",
    "    print('For s =', s, '-->',len(Y_train[Y_train==s])/len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3218230-8fe5-4dfe-8b8d-16c737d57928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training data into one for training and one for validating\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, shuffle=True, random_state=42, stratify=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81131760-d7db-4da8-85f2-fdaf190a3a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 10)\n",
      "(1600, 10)\n",
      "(2000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89261147-90df-4edb-893e-85cea861711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype = torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype = torch.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f906c5-42b0-4dfc-97d9-31e256b9f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset(X_train, Y_train)\n",
    "validation_data = dataset(X_val, Y_val)\n",
    "testing_data = dataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4690fd7-5aff-4277-a762-3d1c2fdbdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(training_data, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4763813f-855a-4796-be1d-242deb7d804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 19:39:13,462] A new study created in memory with name: no-name-05af8223-b9ca-4cf9-978d-61a140510328\n",
      "[I 2025-01-03 19:39:15,347] Trial 0 finished with value: 0.245625 and parameters: {'n_layers': 1, 'n_units_l0': 112, 'dropout_l0': 0.32082664922801496, 'optimizer': 'Adam', 'lr': 2.875137846024102e-05, 'l2': 0.3499685077103457}. Best is trial 0 with value: 0.245625.\n",
      "[I 2025-01-03 19:39:15,910] Trial 1 finished with value: 0.20625 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.28036069163721183, 'optimizer': 'Adam', 'lr': 0.01734219747781515, 'l2': 0.14662901003286385}. Best is trial 0 with value: 0.245625.\n",
      "[I 2025-01-03 19:39:16,561] Trial 2 finished with value: 0.198125 and parameters: {'n_layers': 3, 'n_units_l0': 45, 'dropout_l0': 0.4672409449334567, 'n_units_l1': 100, 'dropout_l1': 0.4398926452547223, 'n_units_l2': 25, 'dropout_l2': 0.4346766748112309, 'optimizer': 'SGD', 'lr': 0.0007473087796621294, 'l2': 0.030438415859914487}. Best is trial 0 with value: 0.245625.\n",
      "[I 2025-01-03 19:39:17,330] Trial 3 finished with value: 0.206875 and parameters: {'n_layers': 2, 'n_units_l0': 66, 'dropout_l0': 0.46443385505670826, 'n_units_l1': 120, 'dropout_l1': 0.261621648349711, 'optimizer': 'SGD', 'lr': 4.3969774431286736e-05, 'l2': 0.019621665037672913}. Best is trial 0 with value: 0.245625.\n",
      "[I 2025-01-03 19:39:17,830] Trial 4 finished with value: 0.36125 and parameters: {'n_layers': 1, 'n_units_l0': 76, 'dropout_l0': 0.4497505743783633, 'optimizer': 'Adam', 'lr': 0.0006800365997711705, 'l2': 0.0005853600191543024}. Best is trial 4 with value: 0.36125.\n",
      "[I 2025-01-03 19:39:18,656] Trial 5 pruned. \n",
      "[I 2025-01-03 19:39:19,074] Trial 6 pruned. \n",
      "[I 2025-01-03 19:39:19,687] Trial 7 pruned. \n",
      "[I 2025-01-03 19:39:19,851] Trial 8 pruned. \n",
      "[I 2025-01-03 19:39:19,988] Trial 9 pruned. \n",
      "[I 2025-01-03 19:39:20,468] Trial 10 pruned. \n",
      "[I 2025-01-03 19:39:20,891] Trial 11 pruned. \n",
      "[I 2025-01-03 19:39:21,411] Trial 12 pruned. \n",
      "[I 2025-01-03 19:39:21,552] Trial 13 pruned. \n",
      "[I 2025-01-03 19:39:21,653] Trial 14 pruned. \n",
      "[I 2025-01-03 19:39:22,212] Trial 15 finished with value: 0.169375 and parameters: {'n_layers': 1, 'n_units_l0': 89, 'dropout_l0': 0.49651040953134995, 'optimizer': 'Adam', 'lr': 4.404463710780484e-05, 'l2': 1.2443324075882194e-05}. Best is trial 4 with value: 0.36125.\n",
      "[I 2025-01-03 19:39:22,856] Trial 16 finished with value: 0.163125 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'dropout_l0': 0.2994804042177981, 'optimizer': 'Adam', 'lr': 0.00027609614702611506, 'l2': 0.08658518834572186}. Best is trial 4 with value: 0.36125.\n",
      "[I 2025-01-03 19:39:23,986] Trial 17 finished with value: 0.20625 and parameters: {'n_layers': 3, 'n_units_l0': 103, 'dropout_l0': 0.20470894064883494, 'n_units_l1': 123, 'dropout_l1': 0.375306530347817, 'n_units_l2': 126, 'dropout_l2': 0.4927880656205037, 'optimizer': 'Adam', 'lr': 0.0023016229119112107, 'l2': 0.0010074563246752666}. Best is trial 4 with value: 0.36125.\n",
      "[I 2025-01-03 19:39:24,054] Trial 18 pruned. \n",
      "[I 2025-01-03 19:39:24,795] Trial 19 finished with value: 0.2 and parameters: {'n_layers': 2, 'n_units_l0': 112, 'dropout_l0': 0.4148136217788265, 'n_units_l1': 82, 'dropout_l1': 0.30543293582247505, 'optimizer': 'RMSprop', 'lr': 3.1054623842469434e-05, 'l2': 5.4785166127204175e-05}. Best is trial 4 with value: 0.36125.\n",
      "[I 2025-01-03 19:39:24,885] Trial 20 pruned. \n",
      "[I 2025-01-03 19:39:25,082] Trial 21 pruned. \n",
      "[I 2025-01-03 19:39:25,193] Trial 22 pruned. \n",
      "[I 2025-01-03 19:39:25,266] Trial 23 pruned. \n",
      "[I 2025-01-03 19:39:25,338] Trial 24 pruned. \n",
      "[I 2025-01-03 19:39:25,420] Trial 25 pruned. \n",
      "[I 2025-01-03 19:39:26,188] Trial 26 finished with value: 0.21 and parameters: {'n_layers': 2, 'n_units_l0': 95, 'dropout_l0': 0.25069232843890593, 'n_units_l1': 109, 'dropout_l1': 0.3375567473797438, 'optimizer': 'Adam', 'lr': 9.023298196361285e-05, 'l2': 0.2562910309300466}. Best is trial 4 with value: 0.36125.\n",
      "[I 2025-01-03 19:39:26,349] Trial 27 pruned. \n",
      "[I 2025-01-03 19:39:26,450] Trial 28 pruned. \n",
      "[I 2025-01-03 19:39:26,519] Trial 29 pruned. \n",
      "[I 2025-01-03 19:39:26,686] Trial 30 pruned. \n",
      "[I 2025-01-03 19:39:26,819] Trial 31 pruned. \n",
      "[I 2025-01-03 19:39:26,938] Trial 32 pruned. \n",
      "[I 2025-01-03 19:39:27,041] Trial 33 pruned. \n",
      "[I 2025-01-03 19:39:27,133] Trial 34 pruned. \n",
      "[I 2025-01-03 19:39:27,268] Trial 35 pruned. \n",
      "[I 2025-01-03 19:39:27,394] Trial 36 pruned. \n",
      "[I 2025-01-03 19:39:27,478] Trial 37 pruned. \n",
      "[I 2025-01-03 19:39:31,913] Trial 38 finished with value: 0.20625 and parameters: {'n_layers': 3, 'n_units_l0': 67, 'dropout_l0': 0.2599726503054466, 'n_units_l1': 128, 'dropout_l1': 0.23955288714393663, 'n_units_l2': 64, 'dropout_l2': 0.4068637329612518, 'optimizer': 'RMSprop', 'lr': 0.006450028193996673, 'l2': 0.00038760958058582624}. Best is trial 4 with value: 0.36125.\n",
      "[I 2025-01-03 19:39:31,998] Trial 39 pruned. \n",
      "[I 2025-01-03 19:39:32,098] Trial 40 pruned. \n",
      "[I 2025-01-03 19:39:32,182] Trial 41 pruned. \n",
      "[I 2025-01-03 19:39:32,806] Trial 42 finished with value: 0.385 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'dropout_l0': 0.33691309759883437, 'optimizer': 'Adam', 'lr': 0.0007282785765373976, 'l2': 0.05246671441828948}. Best is trial 42 with value: 0.385.\n",
      "[I 2025-01-03 19:39:33,362] Trial 43 finished with value: 0.225625 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'dropout_l0': 0.3446139966888099, 'optimizer': 'Adam', 'lr': 0.0005016260669211441, 'l2': 0.04151882580944653}. Best is trial 42 with value: 0.385.\n",
      "[I 2025-01-03 19:39:33,459] Trial 44 pruned. \n",
      "[I 2025-01-03 19:39:33,532] Trial 45 pruned. \n",
      "[I 2025-01-03 19:39:33,614] Trial 46 pruned. \n",
      "[I 2025-01-03 19:39:33,696] Trial 47 pruned. \n",
      "[I 2025-01-03 19:39:34,253] Trial 48 finished with value: 0.40625 and parameters: {'n_layers': 1, 'n_units_l0': 116, 'dropout_l0': 0.30126701801048283, 'optimizer': 'Adam', 'lr': 0.004594925494702763, 'l2': 0.07921858085992974}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:34,900] Trial 49 finished with value: 0.383125 and parameters: {'n_layers': 1, 'n_units_l0': 116, 'dropout_l0': 0.30525451963941697, 'optimizer': 'Adam', 'lr': 0.004134447948456769, 'l2': 0.004184067374716094}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:35,579] Trial 50 finished with value: 0.388125 and parameters: {'n_layers': 1, 'n_units_l0': 115, 'dropout_l0': 0.30364433107388455, 'optimizer': 'Adam', 'lr': 0.005146876533299056, 'l2': 0.00011527533786973013}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:35,677] Trial 51 pruned. \n",
      "[I 2025-01-03 19:39:35,763] Trial 52 pruned. \n",
      "[I 2025-01-03 19:39:35,846] Trial 53 pruned. \n",
      "[I 2025-01-03 19:39:35,929] Trial 54 pruned. \n",
      "[I 2025-01-03 19:39:36,471] Trial 55 finished with value: 0.4 and parameters: {'n_layers': 1, 'n_units_l0': 104, 'dropout_l0': 0.26828225267281314, 'optimizer': 'Adam', 'lr': 0.0020586680135147107, 'l2': 8.539118141975197e-05}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:36,558] Trial 56 pruned. \n",
      "[I 2025-01-03 19:39:36,636] Trial 57 pruned. \n",
      "[I 2025-01-03 19:39:36,776] Trial 58 pruned. \n",
      "[I 2025-01-03 19:39:37,342] Trial 59 finished with value: 0.220625 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.36764081532122417, 'optimizer': 'Adam', 'lr': 0.008893558182255961, 'l2': 1.3401834629047164e-05}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:37,446] Trial 60 pruned. \n",
      "[I 2025-01-03 19:39:37,563] Trial 61 pruned. \n",
      "[I 2025-01-03 19:39:38,120] Trial 62 finished with value: 0.240625 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.33595822898107364, 'optimizer': 'Adam', 'lr': 0.005860151845256548, 'l2': 0.00038280547944337314}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:38,817] Trial 63 finished with value: 0.368125 and parameters: {'n_layers': 1, 'n_units_l0': 111, 'dropout_l0': 0.30624214651354154, 'optimizer': 'Adam', 'lr': 0.0010836453957768404, 'l2': 0.0007311376035061643}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:38,894] Trial 64 pruned. \n",
      "[I 2025-01-03 19:39:38,977] Trial 65 pruned. \n",
      "[I 2025-01-03 19:39:39,061] Trial 66 pruned. \n",
      "[I 2025-01-03 19:39:39,131] Trial 67 pruned. \n",
      "[I 2025-01-03 19:39:39,211] Trial 68 pruned. \n",
      "[I 2025-01-03 19:39:39,754] Trial 69 finished with value: 0.20625 and parameters: {'n_layers': 1, 'n_units_l0': 120, 'dropout_l0': 0.32207503584058494, 'optimizer': 'Adam', 'lr': 0.013281423111350289, 'l2': 8.0648769707876e-05}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:39,842] Trial 70 pruned. \n",
      "[I 2025-01-03 19:39:40,494] Trial 71 finished with value: 0.358125 and parameters: {'n_layers': 1, 'n_units_l0': 111, 'dropout_l0': 0.33675306365980984, 'optimizer': 'Adam', 'lr': 0.0044162875595951155, 'l2': 0.0026549866494154084}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:40,601] Trial 72 pruned. \n",
      "[I 2025-01-03 19:39:41,233] Trial 73 finished with value: 0.40375 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.3079795539148898, 'optimizer': 'Adam', 'lr': 0.004702534950753947, 'l2': 0.0015120912113087115}. Best is trial 48 with value: 0.40625.\n",
      "[I 2025-01-03 19:39:41,792] Trial 74 finished with value: 0.40875 and parameters: {'n_layers': 1, 'n_units_l0': 104, 'dropout_l0': 0.30687207555143603, 'optimizer': 'Adam', 'lr': 0.0013148275493472595, 'l2': 0.0012556345954384234}. Best is trial 74 with value: 0.40875.\n",
      "[I 2025-01-03 19:39:42,489] Trial 75 finished with value: 0.429375 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.30764463943029746, 'optimizer': 'Adam', 'lr': 0.00135550490953752, 'l2': 0.0015705868379809098}. Best is trial 75 with value: 0.429375.\n",
      "[I 2025-01-03 19:39:42,577] Trial 76 pruned. \n",
      "[I 2025-01-03 19:39:43,567] Trial 77 finished with value: 0.299375 and parameters: {'n_layers': 1, 'n_units_l0': 104, 'dropout_l0': 0.32020775279344227, 'optimizer': 'RMSprop', 'lr': 0.0026554145776524793, 'l2': 0.004221422209166106}. Best is trial 75 with value: 0.429375.\n",
      "[I 2025-01-03 19:39:43,659] Trial 78 pruned. \n",
      "[I 2025-01-03 19:39:43,758] Trial 79 pruned. \n",
      "[I 2025-01-03 19:39:43,876] Trial 80 pruned. \n",
      "[I 2025-01-03 19:39:44,724] Trial 81 finished with value: 0.385625 and parameters: {'n_layers': 1, 'n_units_l0': 118, 'dropout_l0': 0.3102732525474231, 'optimizer': 'Adam', 'lr': 0.0020283686833559274, 'l2': 0.0007249266075617983}. Best is trial 75 with value: 0.429375.\n",
      "[I 2025-01-03 19:39:44,815] Trial 82 pruned. \n",
      "[I 2025-01-03 19:39:44,896] Trial 83 pruned. \n",
      "[I 2025-01-03 19:39:44,974] Trial 84 pruned. \n",
      "[I 2025-01-03 19:39:45,662] Trial 85 pruned. \n",
      "[I 2025-01-03 19:39:46,889] Trial 86 finished with value: 0.4575 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.29701832550834834, 'optimizer': 'Adam', 'lr': 0.0018867688979024584, 'l2': 0.011720768517616779}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:47,047] Trial 87 pruned. \n",
      "[I 2025-01-03 19:39:47,189] Trial 88 pruned. \n",
      "[I 2025-01-03 19:39:48,057] Trial 89 finished with value: 0.26 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.2963606191576506, 'optimizer': 'Adam', 'lr': 0.007782640705628277, 'l2': 0.010389145036590485}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:48,140] Trial 90 pruned. \n",
      "[I 2025-01-03 19:39:48,825] Trial 91 finished with value: 0.44 and parameters: {'n_layers': 1, 'n_units_l0': 109, 'dropout_l0': 0.30376680797139216, 'optimizer': 'Adam', 'lr': 0.0020502644609013384, 'l2': 0.0029264442675258407}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:49,454] Trial 92 finished with value: 0.4575 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.3199516962763781, 'optimizer': 'Adam', 'lr': 0.001980354513631656, 'l2': 0.0032795483364140734}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:49,521] Trial 93 pruned. \n",
      "[I 2025-01-03 19:39:49,603] Trial 94 pruned. \n",
      "[I 2025-01-03 19:39:49,668] Trial 95 pruned. \n",
      "[I 2025-01-03 19:39:49,754] Trial 96 pruned. \n",
      "[I 2025-01-03 19:39:50,296] Trial 97 finished with value: 0.40875 and parameters: {'n_layers': 1, 'n_units_l0': 99, 'dropout_l0': 0.27535722286795505, 'optimizer': 'Adam', 'lr': 0.0038835821466837793, 'l2': 0.0012028347712237759}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:50,370] Trial 98 pruned. \n",
      "[I 2025-01-03 19:39:50,998] Trial 99 finished with value: 0.4275 and parameters: {'n_layers': 1, 'n_units_l0': 100, 'dropout_l0': 0.25697627053683425, 'optimizer': 'Adam', 'lr': 0.003082905168528756, 'l2': 0.0012062911900850087}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:51,070] Trial 100 pruned. \n",
      "[I 2025-01-03 19:39:51,153] Trial 101 pruned. \n",
      "[I 2025-01-03 19:39:51,219] Trial 102 pruned. \n",
      "[I 2025-01-03 19:39:51,303] Trial 103 pruned. \n",
      "[I 2025-01-03 19:39:51,855] Trial 104 finished with value: 0.4125 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'dropout_l0': 0.28726389147224757, 'optimizer': 'Adam', 'lr': 0.003634813509438935, 'l2': 0.005441729777185187}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:51,935] Trial 105 pruned. \n",
      "[I 2025-01-03 19:39:52,002] Trial 106 pruned. \n",
      "[I 2025-01-03 19:39:52,545] Trial 107 finished with value: 0.36875 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.27741922904347566, 'optimizer': 'Adam', 'lr': 0.0033292699396450806, 'l2': 0.003396484549616791}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:52,685] Trial 108 pruned. \n",
      "[I 2025-01-03 19:39:52,768] Trial 109 pruned. \n",
      "[I 2025-01-03 19:39:53,227] Trial 110 pruned. \n",
      "[I 2025-01-03 19:39:53,301] Trial 111 pruned. \n",
      "[I 2025-01-03 19:39:53,368] Trial 112 pruned. \n",
      "[I 2025-01-03 19:39:54,019] Trial 113 finished with value: 0.37625 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.25747782709852374, 'optimizer': 'Adam', 'lr': 0.001586513809023124, 'l2': 0.0026747208344305748}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:54,109] Trial 114 pruned. \n",
      "[I 2025-01-03 19:39:54,724] Trial 115 finished with value: 0.315625 and parameters: {'n_layers': 1, 'n_units_l0': 98, 'dropout_l0': 0.27489760709087135, 'optimizer': 'Adam', 'lr': 0.004042484945636349, 'l2': 0.025458079238848852}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:54,798] Trial 116 pruned. \n",
      "[I 2025-01-03 19:39:54,867] Trial 117 pruned. \n",
      "[I 2025-01-03 19:39:55,030] Trial 118 pruned. \n",
      "[I 2025-01-03 19:39:55,560] Trial 119 pruned. \n",
      "[I 2025-01-03 19:39:56,209] Trial 120 finished with value: 0.375625 and parameters: {'n_layers': 1, 'n_units_l0': 122, 'dropout_l0': 0.23630321238126906, 'optimizer': 'Adam', 'lr': 0.001954866815809294, 'l2': 0.0005540053138907384}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:56,297] Trial 121 pruned. \n",
      "[I 2025-01-03 19:39:56,384] Trial 122 pruned. \n",
      "[I 2025-01-03 19:39:56,483] Trial 123 pruned. \n",
      "[I 2025-01-03 19:39:56,568] Trial 124 pruned. \n",
      "[I 2025-01-03 19:39:56,652] Trial 125 pruned. \n",
      "[I 2025-01-03 19:39:56,748] Trial 126 pruned. \n",
      "[I 2025-01-03 19:39:56,831] Trial 127 pruned. \n",
      "[I 2025-01-03 19:39:56,914] Trial 128 pruned. \n",
      "[I 2025-01-03 19:39:57,014] Trial 129 pruned. \n",
      "[I 2025-01-03 19:39:57,112] Trial 130 pruned. \n",
      "[I 2025-01-03 19:39:57,388] Trial 131 pruned. \n",
      "[I 2025-01-03 19:39:57,465] Trial 132 pruned. \n",
      "[I 2025-01-03 19:39:57,550] Trial 133 pruned. \n",
      "[I 2025-01-03 19:39:57,635] Trial 134 pruned. \n",
      "[I 2025-01-03 19:39:57,714] Trial 135 pruned. \n",
      "[I 2025-01-03 19:39:57,799] Trial 136 pruned. \n",
      "[I 2025-01-03 19:39:57,904] Trial 137 pruned. \n",
      "[I 2025-01-03 19:39:58,001] Trial 138 pruned. \n",
      "[I 2025-01-03 19:39:58,085] Trial 139 pruned. \n",
      "[I 2025-01-03 19:39:58,162] Trial 140 pruned. \n",
      "[I 2025-01-03 19:39:58,239] Trial 141 pruned. \n",
      "[I 2025-01-03 19:39:58,314] Trial 142 pruned. \n",
      "[I 2025-01-03 19:39:58,397] Trial 143 pruned. \n",
      "[I 2025-01-03 19:39:58,465] Trial 144 pruned. \n",
      "[I 2025-01-03 19:39:58,551] Trial 145 pruned. \n",
      "[I 2025-01-03 19:39:58,638] Trial 146 pruned. \n",
      "[I 2025-01-03 19:39:58,699] Trial 147 pruned. \n",
      "[I 2025-01-03 19:39:59,224] Trial 148 finished with value: 0.366875 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.29699294875282833, 'optimizer': 'Adam', 'lr': 0.0024144350047061586, 'l2': 9.836751165771067e-05}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:39:59,298] Trial 149 pruned. \n",
      "[I 2025-01-03 19:39:59,380] Trial 150 pruned. \n",
      "[I 2025-01-03 19:39:59,464] Trial 151 pruned. \n",
      "[I 2025-01-03 19:39:59,546] Trial 152 pruned. \n",
      "[I 2025-01-03 19:39:59,711] Trial 153 pruned. \n",
      "[I 2025-01-03 19:39:59,780] Trial 154 pruned. \n",
      "[I 2025-01-03 19:40:00,070] Trial 155 pruned. \n",
      "[I 2025-01-03 19:40:00,153] Trial 156 pruned. \n",
      "[I 2025-01-03 19:40:00,230] Trial 157 pruned. \n",
      "[I 2025-01-03 19:40:00,757] Trial 158 finished with value: 0.418125 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'dropout_l0': 0.2740764987205932, 'optimizer': 'Adam', 'lr': 0.0026724712031781376, 'l2': 0.0021075011535695563}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:00,829] Trial 159 pruned. \n",
      "[I 2025-01-03 19:40:00,954] Trial 160 pruned. \n",
      "[I 2025-01-03 19:40:01,030] Trial 161 pruned. \n",
      "[I 2025-01-03 19:40:01,110] Trial 162 pruned. \n",
      "[I 2025-01-03 19:40:01,180] Trial 163 pruned. \n",
      "[I 2025-01-03 19:40:01,255] Trial 164 pruned. \n",
      "[I 2025-01-03 19:40:01,329] Trial 165 pruned. \n",
      "[I 2025-01-03 19:40:01,430] Trial 166 pruned. \n",
      "[I 2025-01-03 19:40:01,531] Trial 167 pruned. \n",
      "[I 2025-01-03 19:40:01,616] Trial 168 pruned. \n",
      "[I 2025-01-03 19:40:02,856] Trial 169 finished with value: 0.40125 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.3156669669813588, 'optimizer': 'Adam', 'lr': 0.003951495272904607, 'l2': 0.00045629977776329037}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:02,997] Trial 170 pruned. \n",
      "[I 2025-01-03 19:40:03,181] Trial 171 pruned. \n",
      "[I 2025-01-03 19:40:03,357] Trial 172 pruned. \n",
      "[I 2025-01-03 19:40:03,546] Trial 173 pruned. \n",
      "[I 2025-01-03 19:40:03,697] Trial 174 pruned. \n",
      "[I 2025-01-03 19:40:03,895] Trial 175 pruned. \n",
      "[I 2025-01-03 19:40:04,007] Trial 176 pruned. \n",
      "[I 2025-01-03 19:40:04,124] Trial 177 pruned. \n",
      "[I 2025-01-03 19:40:04,229] Trial 178 pruned. \n",
      "[I 2025-01-03 19:40:04,346] Trial 179 pruned. \n",
      "[I 2025-01-03 19:40:04,444] Trial 180 pruned. \n",
      "[I 2025-01-03 19:40:04,546] Trial 181 pruned. \n",
      "[I 2025-01-03 19:40:04,647] Trial 182 pruned. \n",
      "[I 2025-01-03 19:40:04,756] Trial 183 pruned. \n",
      "[I 2025-01-03 19:40:04,846] Trial 184 pruned. \n",
      "[I 2025-01-03 19:40:04,949] Trial 185 pruned. \n",
      "[I 2025-01-03 19:40:05,042] Trial 186 pruned. \n",
      "[I 2025-01-03 19:40:05,790] Trial 187 finished with value: 0.381875 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.23195854937471055, 'optimizer': 'Adam', 'lr': 0.00311914556951948, 'l2': 0.005440720977014847}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:05,875] Trial 188 pruned. \n",
      "[I 2025-01-03 19:40:06,143] Trial 189 pruned. \n",
      "[I 2025-01-03 19:40:06,236] Trial 190 pruned. \n",
      "[I 2025-01-03 19:40:06,330] Trial 191 pruned. \n",
      "[I 2025-01-03 19:40:06,416] Trial 192 pruned. \n",
      "[I 2025-01-03 19:40:06,507] Trial 193 pruned. \n",
      "[I 2025-01-03 19:40:06,595] Trial 194 pruned. \n",
      "[I 2025-01-03 19:40:06,683] Trial 195 pruned. \n",
      "[I 2025-01-03 19:40:06,772] Trial 196 pruned. \n",
      "[I 2025-01-03 19:40:06,860] Trial 197 pruned. \n",
      "[I 2025-01-03 19:40:06,963] Trial 198 pruned. \n",
      "[I 2025-01-03 19:40:07,058] Trial 199 pruned. \n",
      "[I 2025-01-03 19:40:07,162] Trial 200 pruned. \n",
      "[I 2025-01-03 19:40:07,261] Trial 201 pruned. \n",
      "[I 2025-01-03 19:40:07,363] Trial 202 pruned. \n",
      "[I 2025-01-03 19:40:07,459] Trial 203 pruned. \n",
      "[I 2025-01-03 19:40:07,590] Trial 204 pruned. \n",
      "[I 2025-01-03 19:40:08,369] Trial 205 pruned. \n",
      "[I 2025-01-03 19:40:08,632] Trial 206 pruned. \n",
      "[I 2025-01-03 19:40:08,708] Trial 207 pruned. \n",
      "[I 2025-01-03 19:40:08,807] Trial 208 pruned. \n",
      "[I 2025-01-03 19:40:08,908] Trial 209 pruned. \n",
      "[I 2025-01-03 19:40:08,992] Trial 210 pruned. \n",
      "[I 2025-01-03 19:40:09,101] Trial 211 pruned. \n",
      "[I 2025-01-03 19:40:09,201] Trial 212 pruned. \n",
      "[I 2025-01-03 19:40:09,306] Trial 213 pruned. \n",
      "[I 2025-01-03 19:40:09,390] Trial 214 pruned. \n",
      "[I 2025-01-03 19:40:09,605] Trial 215 pruned. \n",
      "[I 2025-01-03 19:40:09,707] Trial 216 pruned. \n",
      "[I 2025-01-03 19:40:09,840] Trial 217 pruned. \n",
      "[I 2025-01-03 19:40:09,946] Trial 218 pruned. \n",
      "[I 2025-01-03 19:40:10,039] Trial 219 pruned. \n",
      "[I 2025-01-03 19:40:10,140] Trial 220 pruned. \n",
      "[I 2025-01-03 19:40:10,223] Trial 221 pruned. \n",
      "[I 2025-01-03 19:40:10,989] Trial 222 finished with value: 0.45375 and parameters: {'n_layers': 1, 'n_units_l0': 95, 'dropout_l0': 0.29396877812440947, 'optimizer': 'Adam', 'lr': 0.0023012087593355986, 'l2': 8.599909578810647e-05}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:11,074] Trial 223 pruned. \n",
      "[I 2025-01-03 19:40:11,156] Trial 224 pruned. \n",
      "[I 2025-01-03 19:40:11,237] Trial 225 pruned. \n",
      "[I 2025-01-03 19:40:11,324] Trial 226 pruned. \n",
      "[I 2025-01-03 19:40:11,406] Trial 227 pruned. \n",
      "[I 2025-01-03 19:40:12,190] Trial 228 pruned. \n",
      "[I 2025-01-03 19:40:12,272] Trial 229 pruned. \n",
      "[I 2025-01-03 19:40:12,372] Trial 230 pruned. \n",
      "[I 2025-01-03 19:40:12,455] Trial 231 pruned. \n",
      "[I 2025-01-03 19:40:12,554] Trial 232 pruned. \n",
      "[I 2025-01-03 19:40:12,648] Trial 233 pruned. \n",
      "[I 2025-01-03 19:40:12,738] Trial 234 pruned. \n",
      "[I 2025-01-03 19:40:12,822] Trial 235 pruned. \n",
      "[I 2025-01-03 19:40:12,905] Trial 236 pruned. \n",
      "[I 2025-01-03 19:40:13,006] Trial 237 pruned. \n",
      "[I 2025-01-03 19:40:13,089] Trial 238 pruned. \n",
      "[I 2025-01-03 19:40:13,172] Trial 239 pruned. \n",
      "[I 2025-01-03 19:40:13,272] Trial 240 pruned. \n",
      "[I 2025-01-03 19:40:13,367] Trial 241 pruned. \n",
      "[I 2025-01-03 19:40:13,453] Trial 242 pruned. \n",
      "[I 2025-01-03 19:40:13,549] Trial 243 pruned. \n",
      "[I 2025-01-03 19:40:13,719] Trial 244 pruned. \n",
      "[I 2025-01-03 19:40:13,820] Trial 245 pruned. \n",
      "[I 2025-01-03 19:40:14,153] Trial 246 pruned. \n",
      "[I 2025-01-03 19:40:14,254] Trial 247 pruned. \n",
      "[I 2025-01-03 19:40:14,337] Trial 248 pruned. \n",
      "[I 2025-01-03 19:40:14,419] Trial 249 pruned. \n",
      "[I 2025-01-03 19:40:14,504] Trial 250 pruned. \n",
      "[I 2025-01-03 19:40:14,588] Trial 251 pruned. \n",
      "[I 2025-01-03 19:40:15,325] Trial 252 finished with value: 0.408125 and parameters: {'n_layers': 1, 'n_units_l0': 106, 'dropout_l0': 0.29656488981119977, 'optimizer': 'Adam', 'lr': 0.0021510479866546674, 'l2': 0.004550294953601609}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:15,422] Trial 253 pruned. \n",
      "[I 2025-01-03 19:40:15,562] Trial 254 pruned. \n",
      "[I 2025-01-03 19:40:15,660] Trial 255 pruned. \n",
      "[I 2025-01-03 19:40:15,751] Trial 256 pruned. \n",
      "[I 2025-01-03 19:40:15,835] Trial 257 pruned. \n",
      "[I 2025-01-03 19:40:15,922] Trial 258 pruned. \n",
      "[I 2025-01-03 19:40:16,003] Trial 259 pruned. \n",
      "[I 2025-01-03 19:40:16,354] Trial 260 pruned. \n",
      "[I 2025-01-03 19:40:16,437] Trial 261 pruned. \n",
      "[I 2025-01-03 19:40:16,519] Trial 262 pruned. \n",
      "[I 2025-01-03 19:40:16,619] Trial 263 pruned. \n",
      "[I 2025-01-03 19:40:16,709] Trial 264 pruned. \n",
      "[I 2025-01-03 19:40:17,117] Trial 265 pruned. \n",
      "[I 2025-01-03 19:40:17,217] Trial 266 pruned. \n",
      "[I 2025-01-03 19:40:17,301] Trial 267 pruned. \n",
      "[I 2025-01-03 19:40:17,387] Trial 268 pruned. \n",
      "[I 2025-01-03 19:40:17,502] Trial 269 pruned. \n",
      "[I 2025-01-03 19:40:17,584] Trial 270 pruned. \n",
      "[I 2025-01-03 19:40:17,681] Trial 271 pruned. \n",
      "[I 2025-01-03 19:40:17,815] Trial 272 pruned. \n",
      "[I 2025-01-03 19:40:17,996] Trial 273 pruned. \n",
      "[I 2025-01-03 19:40:18,153] Trial 274 pruned. \n",
      "[I 2025-01-03 19:40:18,299] Trial 275 pruned. \n",
      "[I 2025-01-03 19:40:18,432] Trial 276 pruned. \n",
      "[I 2025-01-03 19:40:18,585] Trial 277 pruned. \n",
      "[I 2025-01-03 19:40:18,763] Trial 278 pruned. \n",
      "[I 2025-01-03 19:40:18,915] Trial 279 pruned. \n",
      "[I 2025-01-03 19:40:19,072] Trial 280 pruned. \n",
      "[I 2025-01-03 19:40:19,962] Trial 281 pruned. \n",
      "[I 2025-01-03 19:40:20,066] Trial 282 pruned. \n",
      "[I 2025-01-03 19:40:20,149] Trial 283 pruned. \n",
      "[I 2025-01-03 19:40:20,232] Trial 284 pruned. \n",
      "[I 2025-01-03 19:40:20,316] Trial 285 pruned. \n",
      "[I 2025-01-03 19:40:20,399] Trial 286 pruned. \n",
      "[I 2025-01-03 19:40:20,483] Trial 287 pruned. \n",
      "[I 2025-01-03 19:40:21,080] Trial 288 finished with value: 0.429375 and parameters: {'n_layers': 1, 'n_units_l0': 93, 'dropout_l0': 0.2567321648518146, 'optimizer': 'Adam', 'lr': 0.0010158027313050344, 'l2': 0.0008862117089033803}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:21,162] Trial 289 pruned. \n",
      "[I 2025-01-03 19:40:21,281] Trial 290 pruned. \n",
      "[I 2025-01-03 19:40:21,366] Trial 291 pruned. \n",
      "[I 2025-01-03 19:40:21,449] Trial 292 pruned. \n",
      "[I 2025-01-03 19:40:21,532] Trial 293 pruned. \n",
      "[I 2025-01-03 19:40:21,615] Trial 294 pruned. \n",
      "[I 2025-01-03 19:40:21,715] Trial 295 pruned. \n",
      "[I 2025-01-03 19:40:21,783] Trial 296 pruned. \n",
      "[I 2025-01-03 19:40:21,881] Trial 297 pruned. \n",
      "[I 2025-01-03 19:40:21,965] Trial 298 pruned. \n",
      "[I 2025-01-03 19:40:22,048] Trial 299 pruned. \n",
      "[I 2025-01-03 19:40:22,234] Trial 300 pruned. \n",
      "[I 2025-01-03 19:40:22,315] Trial 301 pruned. \n",
      "[I 2025-01-03 19:40:22,398] Trial 302 pruned. \n",
      "[I 2025-01-03 19:40:22,733] Trial 303 pruned. \n",
      "[I 2025-01-03 19:40:22,815] Trial 304 pruned. \n",
      "[I 2025-01-03 19:40:22,897] Trial 305 pruned. \n",
      "[I 2025-01-03 19:40:23,496] Trial 306 finished with value: 0.4125 and parameters: {'n_layers': 1, 'n_units_l0': 102, 'dropout_l0': 0.29234747252880594, 'optimizer': 'Adam', 'lr': 0.0028740390796482993, 'l2': 0.0009627832871725405}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:24,036] Trial 307 pruned. \n",
      "[I 2025-01-03 19:40:24,136] Trial 308 pruned. \n",
      "[I 2025-01-03 19:40:24,214] Trial 309 pruned. \n",
      "[I 2025-01-03 19:40:24,314] Trial 310 pruned. \n",
      "[I 2025-01-03 19:40:24,413] Trial 311 pruned. \n",
      "[I 2025-01-03 19:40:24,496] Trial 312 pruned. \n",
      "[I 2025-01-03 19:40:24,598] Trial 313 pruned. \n",
      "[I 2025-01-03 19:40:24,818] Trial 314 pruned. \n",
      "[I 2025-01-03 19:40:24,948] Trial 315 pruned. \n",
      "[I 2025-01-03 19:40:25,049] Trial 316 pruned. \n",
      "[I 2025-01-03 19:40:25,132] Trial 317 pruned. \n",
      "[I 2025-01-03 19:40:25,232] Trial 318 pruned. \n",
      "[I 2025-01-03 19:40:25,332] Trial 319 pruned. \n",
      "[I 2025-01-03 19:40:25,449] Trial 320 pruned. \n",
      "[I 2025-01-03 19:40:25,667] Trial 321 pruned. \n",
      "[I 2025-01-03 19:40:25,776] Trial 322 pruned. \n",
      "[I 2025-01-03 19:40:25,861] Trial 323 pruned. \n",
      "[I 2025-01-03 19:40:25,947] Trial 324 pruned. \n",
      "[I 2025-01-03 19:40:26,047] Trial 325 pruned. \n",
      "[I 2025-01-03 19:40:26,133] Trial 326 pruned. \n",
      "[I 2025-01-03 19:40:26,214] Trial 327 pruned. \n",
      "[I 2025-01-03 19:40:26,297] Trial 328 pruned. \n",
      "[I 2025-01-03 19:40:26,381] Trial 329 pruned. \n",
      "[I 2025-01-03 19:40:26,481] Trial 330 pruned. \n",
      "[I 2025-01-03 19:40:26,564] Trial 331 pruned. \n",
      "[I 2025-01-03 19:40:26,647] Trial 332 pruned. \n",
      "[I 2025-01-03 19:40:26,747] Trial 333 pruned. \n",
      "[I 2025-01-03 19:40:27,383] Trial 334 finished with value: 0.418125 and parameters: {'n_layers': 1, 'n_units_l0': 100, 'dropout_l0': 0.22608401547713464, 'optimizer': 'Adam', 'lr': 0.0026499433118885975, 'l2': 0.0064216458975977124}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:27,462] Trial 335 pruned. \n",
      "[I 2025-01-03 19:40:28,184] Trial 336 finished with value: 0.385625 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.22855472253940695, 'optimizer': 'SGD', 'lr': 0.002527216774211826, 'l2': 0.005537234461078601}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:28,284] Trial 337 pruned. \n",
      "[I 2025-01-03 19:40:28,362] Trial 338 pruned. \n",
      "[I 2025-01-03 19:40:28,446] Trial 339 pruned. \n",
      "[I 2025-01-03 19:40:28,846] Trial 340 pruned. \n",
      "[I 2025-01-03 19:40:28,929] Trial 341 pruned. \n",
      "[I 2025-01-03 19:40:29,029] Trial 342 pruned. \n",
      "[I 2025-01-03 19:40:29,129] Trial 343 pruned. \n",
      "[I 2025-01-03 19:40:29,445] Trial 344 pruned. \n",
      "[I 2025-01-03 19:40:29,543] Trial 345 pruned. \n",
      "[I 2025-01-03 19:40:29,646] Trial 346 pruned. \n",
      "[I 2025-01-03 19:40:29,821] Trial 347 pruned. \n",
      "[I 2025-01-03 19:40:29,919] Trial 348 pruned. \n",
      "[I 2025-01-03 19:40:29,993] Trial 349 pruned. \n",
      "[I 2025-01-03 19:40:30,085] Trial 350 pruned. \n",
      "[I 2025-01-03 19:40:30,170] Trial 351 pruned. \n",
      "[I 2025-01-03 19:40:30,263] Trial 352 pruned. \n",
      "[I 2025-01-03 19:40:30,361] Trial 353 pruned. \n",
      "[I 2025-01-03 19:40:30,446] Trial 354 pruned. \n",
      "[I 2025-01-03 19:40:30,546] Trial 355 pruned. \n",
      "[I 2025-01-03 19:40:30,639] Trial 356 pruned. \n",
      "[I 2025-01-03 19:40:30,759] Trial 357 pruned. \n",
      "[I 2025-01-03 19:40:30,859] Trial 358 pruned. \n",
      "[I 2025-01-03 19:40:30,943] Trial 359 pruned. \n",
      "[I 2025-01-03 19:40:31,073] Trial 360 pruned. \n",
      "[I 2025-01-03 19:40:31,161] Trial 361 pruned. \n",
      "[I 2025-01-03 19:40:31,245] Trial 362 pruned. \n",
      "[I 2025-01-03 19:40:31,357] Trial 363 pruned. \n",
      "[I 2025-01-03 19:40:31,444] Trial 364 pruned. \n",
      "[I 2025-01-03 19:40:32,093] Trial 365 finished with value: 0.369375 and parameters: {'n_layers': 1, 'n_units_l0': 102, 'dropout_l0': 0.26344014847802916, 'optimizer': 'Adam', 'lr': 0.003401588820312991, 'l2': 0.0012007040095254884}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:32,444] Trial 366 pruned. \n",
      "[I 2025-01-03 19:40:32,543] Trial 367 pruned. \n",
      "[I 2025-01-03 19:40:32,643] Trial 368 pruned. \n",
      "[I 2025-01-03 19:40:32,743] Trial 369 pruned. \n",
      "[I 2025-01-03 19:40:33,009] Trial 370 pruned. \n",
      "[I 2025-01-03 19:40:33,109] Trial 371 pruned. \n",
      "[I 2025-01-03 19:40:33,223] Trial 372 pruned. \n",
      "[I 2025-01-03 19:40:33,328] Trial 373 pruned. \n",
      "[I 2025-01-03 19:40:33,428] Trial 374 pruned. \n",
      "[I 2025-01-03 19:40:34,409] Trial 375 finished with value: 0.424375 and parameters: {'n_layers': 1, 'n_units_l0': 81, 'dropout_l0': 0.3009084047094655, 'optimizer': 'Adam', 'lr': 0.0008989105524721647, 'l2': 8.690264093170528e-05}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:34,575] Trial 376 pruned. \n",
      "[I 2025-01-03 19:40:34,742] Trial 377 pruned. \n",
      "[I 2025-01-03 19:40:34,909] Trial 378 pruned. \n",
      "[I 2025-01-03 19:40:35,096] Trial 379 pruned. \n",
      "[I 2025-01-03 19:40:35,241] Trial 380 pruned. \n",
      "[I 2025-01-03 19:40:35,408] Trial 381 pruned. \n",
      "[I 2025-01-03 19:40:35,555] Trial 382 pruned. \n",
      "[I 2025-01-03 19:40:36,087] Trial 383 pruned. \n",
      "[I 2025-01-03 19:40:36,191] Trial 384 pruned. \n",
      "[I 2025-01-03 19:40:36,291] Trial 385 pruned. \n",
      "[I 2025-01-03 19:40:36,372] Trial 386 pruned. \n",
      "[I 2025-01-03 19:40:36,455] Trial 387 pruned. \n",
      "[I 2025-01-03 19:40:36,539] Trial 388 pruned. \n",
      "[I 2025-01-03 19:40:36,641] Trial 389 pruned. \n",
      "[I 2025-01-03 19:40:36,758] Trial 390 pruned. \n",
      "[I 2025-01-03 19:40:36,840] Trial 391 pruned. \n",
      "[I 2025-01-03 19:40:36,940] Trial 392 pruned. \n",
      "[I 2025-01-03 19:40:37,040] Trial 393 pruned. \n",
      "[I 2025-01-03 19:40:37,624] Trial 394 finished with value: 0.439375 and parameters: {'n_layers': 1, 'n_units_l0': 66, 'dropout_l0': 0.2969466940072919, 'optimizer': 'Adam', 'lr': 0.0019792237188595778, 'l2': 0.0018081981994149002}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:37,723] Trial 395 pruned. \n",
      "[I 2025-01-03 19:40:37,806] Trial 396 pruned. \n",
      "[I 2025-01-03 19:40:37,905] Trial 397 pruned. \n",
      "[I 2025-01-03 19:40:38,006] Trial 398 pruned. \n",
      "[I 2025-01-03 19:40:38,106] Trial 399 pruned. \n",
      "[I 2025-01-03 19:40:38,252] Trial 400 pruned. \n",
      "[I 2025-01-03 19:40:38,341] Trial 401 pruned. \n",
      "[I 2025-01-03 19:40:38,440] Trial 402 pruned. \n",
      "[I 2025-01-03 19:40:38,601] Trial 403 pruned. \n",
      "[I 2025-01-03 19:40:38,693] Trial 404 pruned. \n",
      "[I 2025-01-03 19:40:38,801] Trial 405 pruned. \n",
      "[I 2025-01-03 19:40:39,037] Trial 406 pruned. \n",
      "[I 2025-01-03 19:40:39,130] Trial 407 pruned. \n",
      "[I 2025-01-03 19:40:39,219] Trial 408 pruned. \n",
      "[I 2025-01-03 19:40:39,294] Trial 409 pruned. \n",
      "[I 2025-01-03 19:40:39,390] Trial 410 pruned. \n",
      "[I 2025-01-03 19:40:39,471] Trial 411 pruned. \n",
      "[I 2025-01-03 19:40:39,569] Trial 412 pruned. \n",
      "[I 2025-01-03 19:40:40,338] Trial 413 finished with value: 0.37625 and parameters: {'n_layers': 1, 'n_units_l0': 113, 'dropout_l0': 0.26902361144177983, 'optimizer': 'Adam', 'lr': 0.0019924422081042444, 'l2': 5.0785982751143175e-05}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:40,438] Trial 414 pruned. \n",
      "[I 2025-01-03 19:40:40,521] Trial 415 pruned. \n",
      "[I 2025-01-03 19:40:40,622] Trial 416 pruned. \n",
      "[I 2025-01-03 19:40:40,741] Trial 417 pruned. \n",
      "[I 2025-01-03 19:40:41,097] Trial 418 pruned. \n",
      "[I 2025-01-03 19:40:41,200] Trial 419 pruned. \n",
      "[I 2025-01-03 19:40:41,286] Trial 420 pruned. \n",
      "[I 2025-01-03 19:40:41,386] Trial 421 pruned. \n",
      "[I 2025-01-03 19:40:41,506] Trial 422 pruned. \n",
      "[I 2025-01-03 19:40:42,033] Trial 423 pruned. \n",
      "[I 2025-01-03 19:40:42,187] Trial 424 pruned. \n",
      "[I 2025-01-03 19:40:42,319] Trial 425 pruned. \n",
      "[I 2025-01-03 19:40:42,418] Trial 426 pruned. \n",
      "[I 2025-01-03 19:40:42,498] Trial 427 pruned. \n",
      "[I 2025-01-03 19:40:42,587] Trial 428 pruned. \n",
      "[I 2025-01-03 19:40:42,708] Trial 429 pruned. \n",
      "[I 2025-01-03 19:40:42,804] Trial 430 pruned. \n",
      "[I 2025-01-03 19:40:43,420] Trial 431 finished with value: 0.394375 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.2879994845914017, 'optimizer': 'Adam', 'lr': 0.0026593038086511907, 'l2': 0.0014143529904511848}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:43,518] Trial 432 pruned. \n",
      "[I 2025-01-03 19:40:44,280] Trial 433 finished with value: 0.379375 and parameters: {'n_layers': 1, 'n_units_l0': 57, 'dropout_l0': 0.28420996289465567, 'optimizer': 'Adam', 'lr': 0.0022358810311939245, 'l2': 0.0009223677311844185}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:44,800] Trial 434 finished with value: 0.41 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.29132298179174454, 'optimizer': 'SGD', 'lr': 0.0027066437113639928, 'l2': 0.0010687479099420686}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:45,101] Trial 435 pruned. \n",
      "[I 2025-01-03 19:40:45,185] Trial 436 pruned. \n",
      "[I 2025-01-03 19:40:45,284] Trial 437 pruned. \n",
      "[I 2025-01-03 19:40:45,863] Trial 438 finished with value: 0.3925 and parameters: {'n_layers': 1, 'n_units_l0': 82, 'dropout_l0': 0.28882147176173406, 'optimizer': 'SGD', 'lr': 0.0025261756149055925, 'l2': 0.0009805549023271872}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:45,980] Trial 439 pruned. \n",
      "[I 2025-01-03 19:40:46,084] Trial 440 pruned. \n",
      "[I 2025-01-03 19:40:46,184] Trial 441 pruned. \n",
      "[I 2025-01-03 19:40:46,519] Trial 442 pruned. \n",
      "[I 2025-01-03 19:40:47,103] Trial 443 finished with value: 0.38625 and parameters: {'n_layers': 1, 'n_units_l0': 81, 'dropout_l0': 0.2718675030879535, 'optimizer': 'SGD', 'lr': 0.0020909461824255224, 'l2': 0.0009635549497675833}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:47,203] Trial 444 pruned. \n",
      "[I 2025-01-03 19:40:47,282] Trial 445 pruned. \n",
      "[I 2025-01-03 19:40:47,383] Trial 446 pruned. \n",
      "[I 2025-01-03 19:40:47,466] Trial 447 pruned. \n",
      "[I 2025-01-03 19:40:48,005] Trial 448 finished with value: 0.405625 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.27325287628171085, 'optimizer': 'SGD', 'lr': 0.002608763034850901, 'l2': 0.0010402360712636935}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:48,269] Trial 449 pruned. \n",
      "[I 2025-01-03 19:40:48,932] Trial 450 finished with value: 0.379375 and parameters: {'n_layers': 1, 'n_units_l0': 87, 'dropout_l0': 0.2803404284646653, 'optimizer': 'SGD', 'lr': 0.0026026324315148635, 'l2': 0.0012774903310972673}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:49,032] Trial 451 pruned. \n",
      "[I 2025-01-03 19:40:49,422] Trial 452 pruned. \n",
      "[I 2025-01-03 19:40:49,504] Trial 453 pruned. \n",
      "[I 2025-01-03 19:40:50,394] Trial 454 finished with value: 0.415625 and parameters: {'n_layers': 1, 'n_units_l0': 74, 'dropout_l0': 0.2769776260628342, 'optimizer': 'SGD', 'lr': 0.002530794829241716, 'l2': 0.0013000502243554531}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:50,528] Trial 455 pruned. \n",
      "[I 2025-01-03 19:40:50,694] Trial 456 pruned. \n",
      "[I 2025-01-03 19:40:51,299] Trial 457 pruned. \n",
      "[I 2025-01-03 19:40:52,054] Trial 458 finished with value: 0.428125 and parameters: {'n_layers': 1, 'n_units_l0': 74, 'dropout_l0': 0.27355006230012935, 'optimizer': 'SGD', 'lr': 0.001929938274959611, 'l2': 0.000931649274232177}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:52,145] Trial 459 pruned. \n",
      "[I 2025-01-03 19:40:52,247] Trial 460 pruned. \n",
      "[I 2025-01-03 19:40:52,852] Trial 461 finished with value: 0.354375 and parameters: {'n_layers': 1, 'n_units_l0': 70, 'dropout_l0': 0.2746041630342578, 'optimizer': 'SGD', 'lr': 0.0018737169599687264, 'l2': 0.0013299629483680758}. Best is trial 86 with value: 0.4575.\n",
      "[I 2025-01-03 19:40:52,967] Trial 462 pruned. \n",
      "[I 2025-01-03 19:40:53,083] Trial 463 pruned. \n",
      "[I 2025-01-03 19:40:53,180] Trial 464 pruned. \n",
      "[I 2025-01-03 19:40:53,263] Trial 465 pruned. \n",
      "[I 2025-01-03 19:40:53,377] Trial 466 pruned. \n",
      "[I 2025-01-03 19:40:53,478] Trial 467 pruned. \n",
      "[I 2025-01-03 19:40:53,599] Trial 468 pruned. \n",
      "[I 2025-01-03 19:40:53,790] Trial 469 pruned. \n",
      "[I 2025-01-03 19:40:53,894] Trial 470 pruned. \n",
      "[I 2025-01-03 19:40:53,978] Trial 471 pruned. \n",
      "[I 2025-01-03 19:40:54,511] Trial 472 pruned. \n",
      "[I 2025-01-03 19:40:54,595] Trial 473 pruned. \n",
      "[I 2025-01-03 19:40:55,012] Trial 474 pruned. \n",
      "[I 2025-01-03 19:40:55,126] Trial 475 pruned. \n",
      "[I 2025-01-03 19:40:55,327] Trial 476 pruned. \n",
      "[I 2025-01-03 19:40:55,426] Trial 477 pruned. \n",
      "[I 2025-01-03 19:40:55,526] Trial 478 pruned. \n",
      "[I 2025-01-03 19:40:55,622] Trial 479 pruned. \n",
      "[I 2025-01-03 19:40:55,708] Trial 480 pruned. \n",
      "[I 2025-01-03 19:40:55,795] Trial 481 pruned. \n",
      "[I 2025-01-03 19:40:56,194] Trial 482 pruned. \n",
      "[I 2025-01-03 19:40:56,371] Trial 483 pruned. \n",
      "[I 2025-01-03 19:40:56,462] Trial 484 pruned. \n",
      "[I 2025-01-03 19:40:56,543] Trial 485 pruned. \n",
      "[I 2025-01-03 19:40:56,628] Trial 486 pruned. \n",
      "[I 2025-01-03 19:40:56,728] Trial 487 pruned. \n",
      "[I 2025-01-03 19:40:56,825] Trial 488 pruned. \n",
      "[I 2025-01-03 19:40:57,156] Trial 489 pruned. \n",
      "[I 2025-01-03 19:40:57,244] Trial 490 pruned. \n",
      "[I 2025-01-03 19:40:57,342] Trial 491 pruned. \n",
      "[I 2025-01-03 19:40:57,425] Trial 492 pruned. \n",
      "[I 2025-01-03 19:40:57,524] Trial 493 pruned. \n",
      "[I 2025-01-03 19:40:57,627] Trial 494 pruned. \n",
      "[I 2025-01-03 19:40:57,735] Trial 495 pruned. \n",
      "[I 2025-01-03 19:40:57,876] Trial 496 pruned. \n",
      "[I 2025-01-03 19:40:57,974] Trial 497 pruned. \n",
      "[I 2025-01-03 19:40:58,077] Trial 498 pruned. \n",
      "[I 2025-01-03 19:40:58,213] Trial 499 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  500\n",
      "  Number of pruned trials:  438\n",
      "  Number of complete trials:  62\n",
      "Best trial:\n",
      "  Value:  0.4575\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 97\n",
      "    dropout_l0: 0.29701832550834834\n",
      "    optimizer: Adam\n",
      "    lr: 0.0018867688979024584\n",
      "    l2: 0.011720768517616779\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10 #epochs are fixed to simplify the tuning\n",
    "\n",
    "#defining the hyperparameter space of the model hyperparameters\n",
    "def define_model(trial):\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3) #layers can take any number between 1 and 3\n",
    "    layers = []\n",
    "\n",
    "    in_features = num_features\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128) #number of unites/layer can take any number between 4 and 128\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5) #the dropoout probability can take any float number between 0.2 and 0.5\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, len(s_values)))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "#defining the hyperparameter space of the objective function hyperparameters\n",
    "def objective(trial):\n",
    "    \n",
    "    model = define_model(trial)\n",
    "\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    l2 = trial.suggest_float(\"l2\", 1e-5, 1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=l2)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            targets = targets - 1 #substracting one to be consistent with what Cross Entropy Loss in PyTorch expect\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(validation_data.X)\n",
    "            #print(\"y_pred1\", y_pred)\n",
    "            y_pred = torch.argmax(y_pred, dim=1).numpy() # Transformation of the dummy variable to the class index\n",
    "            #print(\"y_pred2\", y_pred)\n",
    "            y_true = validation_data.Y - 1\n",
    "            #print(\"y_true\", y_true)\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "        trial.report(acc, epoch)\n",
    "\n",
    "        #Pruning unpromising trials to save time\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return acc # returning the metric that direct the bayesian optimization\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\") #The metric is to maximize\n",
    "    study.optimize(objective, n_trials=500) #The number of trials is 500\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1892b09a-39fa-4b46-9187-35aa4c6bd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model with best parameter on the training data\n",
    "#The corect way is to train on the training data including the validation data\n",
    "#But here I didn't include it for time reasons\n",
    "best_model = define_model(trial)\n",
    "best_optimizer = getattr(optim, trial.params[\"optimizer\"])(\n",
    "    best_model.parameters(),\n",
    "    lr=trial.params[\"lr\"],\n",
    "    weight_decay=trial.params[\"l2\"]\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_model.train()\n",
    "for inputs, targets in trainloader:\n",
    "    best_optimizer.zero_grad()\n",
    "    outputs = best_model(inputs)\n",
    "    targets = targets - 1 \n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    best_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e28d740-995b-4ad8-a95d-9d922de7170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.201\n"
     ]
    }
   ],
   "source": [
    "#evaluating on the test data gives 0.201, which show that the model perform as a uniform guesser because each class has the proportion 1/5 = 0.2.\n",
    "#The problem might be an underfitting or an inconsistency in the code\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(testing_data.X)\n",
    "    test_pred = torch.argmax(test_outputs, dim=1).numpy()\n",
    "    test_true = testing_data.Y - 1\n",
    "    test_accuracy = accuracy_score(test_true, test_pred)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
